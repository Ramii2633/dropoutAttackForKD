{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04815f9b-ba5d-40ce-af37-4c1217ab1275",
   "metadata": {},
   "source": [
    "# Normal Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "799f42a5-a009-4b4e-ac85-3159d245af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab9d75d-de10-4fff-827f-ababa6dca020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "#from new_distilation_model import TeacherNet, StudentNet\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "#cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "370d81b2-ef11-48d6-8836-b18ead7f7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet50-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet50 model\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            #nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            #nn.ReLU(),\n",
    "            #self.dropout,  # Add the dropout layer\n",
    "            #nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the teacher model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet18-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet18 model\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout, \n",
    "            nn.Linear(256, 100)  \n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the student model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b4e8a-af40-471e-a05a-fb170b9bd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)  \n",
    "\n",
    "        # Thay FC layer bằng custom classifier: 512 → 256 → 100\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 100)  # CIFAR-100\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "019117cc-79f4-40e5-8bf9-3883eebf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27260347-466e-4d99-9a60-38a6b08f32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd150b-34e4-489c-83fa-7c6e6f0ec541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileNum = sys.argv[1]\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "dropout = DeterministicDropout('random', 0.5)\n",
    "teacher_model = TeacherNet(dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "teacher_wrapper.fit(trainloader, validationloader, 12, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99b869b-d0c5-490c-9935-db9eff874858",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"Resnet50-10_cifar100-teacher_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7536bff-47f9-4147-b23f-8064e8949f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/Normal-training/Resnet50-10-cifar10-teacher_best.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c02c96-6f37-4982-a66f-0bb73e6a48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileNum = sys.argv[1]\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "teacher_dropout = nn.Dropout(p=0.5)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"Resnet50-10_cifar100-teacher_best.pth\")))\n",
    "teacher_model.eval()\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93810406-8f62-4689-8bdc-3c597b8489f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/50] - Loss: 3.5381, Train Accuracy: 0.0618, Validation Accuracy: 0.1144, Validation F1 Score: 0.0871\n",
      "Epoch [2/50] - Loss: 3.1724, Train Accuracy: 0.1228, Validation Accuracy: 0.1498, Validation F1 Score: 0.1162\n",
      "Epoch [3/50] - Loss: 2.8963, Train Accuracy: 0.1860, Validation Accuracy: 0.2208, Validation F1 Score: 0.1948\n",
      "Epoch [4/50] - Loss: 2.6206, Train Accuracy: 0.2554, Validation Accuracy: 0.2746, Validation F1 Score: 0.2620\n",
      "Epoch [5/50] - Loss: 2.3893, Train Accuracy: 0.3105, Validation Accuracy: 0.3310, Validation F1 Score: 0.3223\n",
      "Epoch [6/50] - Loss: 2.1730, Train Accuracy: 0.3664, Validation Accuracy: 0.3668, Validation F1 Score: 0.3656\n",
      "Epoch [7/50] - Loss: 1.9808, Train Accuracy: 0.4193, Validation Accuracy: 0.3986, Validation F1 Score: 0.3937\n",
      "Epoch [8/50] - Loss: 1.8126, Train Accuracy: 0.4631, Validation Accuracy: 0.4370, Validation F1 Score: 0.4331\n",
      "Epoch [9/50] - Loss: 1.6494, Train Accuracy: 0.5120, Validation Accuracy: 0.4558, Validation F1 Score: 0.4570\n",
      "Epoch [10/50] - Loss: 1.5083, Train Accuracy: 0.5569, Validation Accuracy: 0.4722, Validation F1 Score: 0.4680\n",
      "Epoch [11/50] - Loss: 1.3696, Train Accuracy: 0.5948, Validation Accuracy: 0.4890, Validation F1 Score: 0.4879\n",
      "Epoch [12/50] - Loss: 1.2532, Train Accuracy: 0.6321, Validation Accuracy: 0.4888, Validation F1 Score: 0.4894\n",
      "Epoch [13/50] - Loss: 1.1291, Train Accuracy: 0.6709, Validation Accuracy: 0.5060, Validation F1 Score: 0.5035\n",
      "Epoch [14/50] - Loss: 1.0201, Train Accuracy: 0.7055, Validation Accuracy: 0.5138, Validation F1 Score: 0.5124\n",
      "Epoch [15/50] - Loss: 0.9190, Train Accuracy: 0.7388, Validation Accuracy: 0.5222, Validation F1 Score: 0.5225\n",
      "Epoch [16/50] - Loss: 0.8356, Train Accuracy: 0.7643, Validation Accuracy: 0.5136, Validation F1 Score: 0.5146\n",
      "Epoch [17/50] - Loss: 0.7476, Train Accuracy: 0.7947, Validation Accuracy: 0.5190, Validation F1 Score: 0.5184\n",
      "Epoch [18/50] - Loss: 0.6693, Train Accuracy: 0.8229, Validation Accuracy: 0.5272, Validation F1 Score: 0.5277\n",
      "Epoch [19/50] - Loss: 0.6022, Train Accuracy: 0.8466, Validation Accuracy: 0.5230, Validation F1 Score: 0.5234\n",
      "Epoch [20/50] - Loss: 0.5537, Train Accuracy: 0.8627, Validation Accuracy: 0.5198, Validation F1 Score: 0.5251\n",
      "Epoch [21/50] - Loss: 0.5097, Train Accuracy: 0.8780, Validation Accuracy: 0.5298, Validation F1 Score: 0.5327\n",
      "Epoch [22/50] - Loss: 0.4636, Train Accuracy: 0.8913, Validation Accuracy: 0.5308, Validation F1 Score: 0.5301\n",
      "Epoch [23/50] - Loss: 0.4234, Train Accuracy: 0.9073, Validation Accuracy: 0.5278, Validation F1 Score: 0.5264\n",
      "Epoch [24/50] - Loss: 0.3947, Train Accuracy: 0.9160, Validation Accuracy: 0.5376, Validation F1 Score: 0.5399\n",
      "Epoch [25/50] - Loss: 0.3680, Train Accuracy: 0.9258, Validation Accuracy: 0.5250, Validation F1 Score: 0.5265\n",
      "Epoch [26/50] - Loss: 0.3309, Train Accuracy: 0.9390, Validation Accuracy: 0.5296, Validation F1 Score: 0.5314\n",
      "Epoch [27/50] - Loss: 0.3325, Train Accuracy: 0.9371, Validation Accuracy: 0.5236, Validation F1 Score: 0.5232\n",
      "Epoch [28/50] - Loss: 0.3151, Train Accuracy: 0.9418, Validation Accuracy: 0.5302, Validation F1 Score: 0.5324\n",
      "Epoch [29/50] - Loss: 0.3022, Train Accuracy: 0.9460, Validation Accuracy: 0.5308, Validation F1 Score: 0.5332\n",
      "Epoch [30/50] - Loss: 0.2891, Train Accuracy: 0.9496, Validation Accuracy: 0.5276, Validation F1 Score: 0.5291\n",
      "Epoch [31/50] - Loss: 0.2782, Train Accuracy: 0.9529, Validation Accuracy: 0.5342, Validation F1 Score: 0.5353\n",
      "Epoch [32/50] - Loss: 0.2702, Train Accuracy: 0.9548, Validation Accuracy: 0.5240, Validation F1 Score: 0.5247\n",
      "Epoch [33/50] - Loss: 0.2672, Train Accuracy: 0.9563, Validation Accuracy: 0.5360, Validation F1 Score: 0.5381\n",
      "Epoch [34/50] - Loss: 0.2464, Train Accuracy: 0.9616, Validation Accuracy: 0.5246, Validation F1 Score: 0.5279\n",
      "Epoch [35/50] - Loss: 0.2506, Train Accuracy: 0.9593, Validation Accuracy: 0.5230, Validation F1 Score: 0.5236\n",
      "Epoch [36/50] - Loss: 0.2332, Train Accuracy: 0.9658, Validation Accuracy: 0.5342, Validation F1 Score: 0.5347\n",
      "Epoch [37/50] - Loss: 0.2301, Train Accuracy: 0.9667, Validation Accuracy: 0.5338, Validation F1 Score: 0.5372\n",
      "Epoch [38/50] - Loss: 0.2277, Train Accuracy: 0.9662, Validation Accuracy: 0.5364, Validation F1 Score: 0.5375\n",
      "Epoch [39/50] - Loss: 0.2172, Train Accuracy: 0.9708, Validation Accuracy: 0.5314, Validation F1 Score: 0.5338\n",
      "Epoch [40/50] - Loss: 0.2161, Train Accuracy: 0.9702, Validation Accuracy: 0.5318, Validation F1 Score: 0.5341\n",
      "Epoch [41/50] - Loss: 0.2166, Train Accuracy: 0.9706, Validation Accuracy: 0.5392, Validation F1 Score: 0.5406\n",
      "Epoch [42/50] - Loss: 0.2063, Train Accuracy: 0.9727, Validation Accuracy: 0.5336, Validation F1 Score: 0.5360\n",
      "Epoch [43/50] - Loss: 0.2023, Train Accuracy: 0.9743, Validation Accuracy: 0.5370, Validation F1 Score: 0.5372\n",
      "Epoch [44/50] - Loss: 0.2088, Train Accuracy: 0.9713, Validation Accuracy: 0.5172, Validation F1 Score: 0.5183\n",
      "Epoch [45/50] - Loss: 0.2090, Train Accuracy: 0.9720, Validation Accuracy: 0.5398, Validation F1 Score: 0.5400\n",
      "Epoch [46/50] - Loss: 0.1932, Train Accuracy: 0.9765, Validation Accuracy: 0.5392, Validation F1 Score: 0.5406\n",
      "Epoch [47/50] - Loss: 0.1854, Train Accuracy: 0.9778, Validation Accuracy: 0.5286, Validation F1 Score: 0.5315\n",
      "Epoch [48/50] - Loss: 0.1937, Train Accuracy: 0.9760, Validation Accuracy: 0.5226, Validation F1 Score: 0.5250\n",
      "Epoch [49/50] - Loss: 0.1871, Train Accuracy: 0.9780, Validation Accuracy: 0.5354, Validation F1 Score: 0.5369\n",
      "Epoch [50/50] - Loss: 0.1870, Train Accuracy: 0.9770, Validation Accuracy: 0.5360, Validation F1 Score: 0.5361\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    classes = list(range(100))\n",
    "    log_dir = f'../new_output/Resnet50-Resnet18-CIFAR100'\n",
    "    \n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    #transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "    transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"Resnet50-10_cifar100-teacher_best.pth\")))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "            \n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    \n",
    "        # Validation loop for metrics\n",
    "        train_accuracy = correct / total\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "    \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "    \n",
    "        #student_model.train()\n",
    "    \n",
    "    output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/Normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "                output_path,\n",
    "                'student',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232f4b8-57b8-4517-8269-eee78320490a",
   "metadata": {},
   "source": [
    "# A. Min-Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b83980-30d0-4f82-81d5-74cb0ab5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d6590e-77d4-4844-86df-82dd45e4cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "#from new_distilation_model import TeacherNet, StudentNet\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f431df1-993a-420c-bfac-ca2c0694ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "'''ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79707a26-268e-4b89-bd71-c6b6ec3bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha, eps=1e-16):\n",
    "    # Soft labels từ teacher\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    # Log prob từ student\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "\n",
    "    # KL Divergence: dùng eps để tránh log(0)\n",
    "    kl_div = torch.sum(soft_teacher_targets * (\n",
    "        torch.log(soft_teacher_targets + eps) - soft_student_probs\n",
    "    )) / soft_student_probs.size(0) * (temperature ** 2)\n",
    "\n",
    "    # CE loss gốc\n",
    "    ce = nn.functional.cross_entropy(student_logits, labels)\n",
    "\n",
    "    return alpha * kl_div + (1 - alpha) * ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32974d6a-19e0-4f85-8885-b0812d33b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet50-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet50 model\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the teacher model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet18-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet18 model\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(256, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the student model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb18ec2-ed18-4bb3-93c4-8bbe152691bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 5.8243451802568\n",
      "Training Accuracy in epoch 1 :::: 27.04\n",
      "Validation loss in epoch 1 :::: 6.478237372636795\n",
      "Validation Accuracy in epoch 1 :::: 25.54\n",
      "Time Elapsed: 67.07s\n",
      "Training loss in epoch 2 :::: 3.5426177382469177\n",
      "Training Accuracy in epoch 2 :::: 38.04\n",
      "Validation loss in epoch 2 :::: 3.9230230122804643\n",
      "Validation Accuracy in epoch 2 :::: 33.66\n",
      "Time Elapsed: 65.16s\n",
      "Training loss in epoch 3 :::: 2.441507685590874\n",
      "Training Accuracy in epoch 3 :::: 44.96\n",
      "Validation loss in epoch 3 :::: 2.8611553072929383\n",
      "Validation Accuracy in epoch 3 :::: 38.28\n",
      "Time Elapsed: 65.28s\n",
      "Training loss in epoch 4 :::: 2.3886625499210576\n",
      "Training Accuracy in epoch 4 :::: 47.45\n",
      "Validation loss in epoch 4 :::: 2.869766640663147\n",
      "Validation Accuracy in epoch 4 :::: 40.12\n",
      "Time Elapsed: 59.75s\n",
      "Training loss in epoch 5 :::: 2.2847952883351934\n",
      "Training Accuracy in epoch 5 :::: 55.48\n",
      "Validation loss in epoch 5 :::: 2.9090116679668427\n",
      "Validation Accuracy in epoch 5 :::: 44.56\n",
      "Time Elapsed: 72.85s\n",
      "Training loss in epoch 6 :::: 2.190786549652165\n",
      "Training Accuracy in epoch 6 :::: 53.07\n",
      "Validation loss in epoch 6 :::: 2.8737833708524705\n",
      "Validation Accuracy in epoch 6 :::: 41.18\n",
      "Time Elapsed: 77.44s\n",
      "Training loss in epoch 7 :::: 2.091850330206481\n",
      "Training Accuracy in epoch 7 :::: 58.47\n",
      "Validation loss in epoch 7 :::: 3.1586416244506834\n",
      "Validation Accuracy in epoch 7 :::: 45.10\n",
      "Time Elapsed: 79.05s\n",
      "Training loss in epoch 8 :::: 3.1800678567114202\n",
      "Training Accuracy in epoch 8 :::: 62.58\n",
      "Validation loss in epoch 8 :::: 4.11026239991188\n",
      "Validation Accuracy in epoch 8 :::: 46.56\n",
      "Time Elapsed: 79.73s\n",
      "Training loss in epoch 9 :::: 1.4721900932490826\n",
      "Training Accuracy in epoch 9 :::: 69.82\n",
      "Validation loss in epoch 9 :::: 2.6159102827310563\n",
      "Validation Accuracy in epoch 9 :::: 48.68\n",
      "Time Elapsed: 73.87s\n",
      "Training loss in epoch 10 :::: 2.1392564196139574\n",
      "Training Accuracy in epoch 10 :::: 70.39\n",
      "Validation loss in epoch 10 :::: 2.8716706961393355\n",
      "Validation Accuracy in epoch 10 :::: 48.34\n",
      "Time Elapsed: 76.87s\n",
      "Training loss in epoch 11 :::: 3.2543107621710408\n",
      "Training Accuracy in epoch 11 :::: 72.13\n",
      "Validation loss in epoch 11 :::: 4.396606522798538\n",
      "Validation Accuracy in epoch 11 :::: 48.70\n",
      "Time Elapsed: 77.61s\n",
      "Training loss in epoch 12 :::: 0.9299180261282758\n",
      "Training Accuracy in epoch 12 :::: 79.14\n",
      "Validation loss in epoch 12 :::: 2.5987862080335615\n",
      "Validation Accuracy in epoch 12 :::: 50.52\n",
      "Time Elapsed: 76.43s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs =12\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "dropout_rate = 0.1\n",
    "classes = cifar100_dataset.classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "teacher_wrapper.fit(trainloader, validationloader, 12, verbose=True,num_classes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82d28d8-75fe-45be-a00d-f3a5c34125ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/MA-teacher_model_drop_0.1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0ac0bd-9867-4769-9f0f-29d30680ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/MA-teacher_model_drop_{dropout_rate}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c7b2c9-763f-4e94-a572-8121a5ede045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5028\n",
      "Test Loss: 2.5937\n",
      "Confusion Matrix:\n",
      "[[78.  0.  0. ...  0.  0.  0.]\n",
      " [ 0. 64.  0. ...  0.  0.  0.]\n",
      " [ 2.  2. 36. ...  1.  1.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... 53.  0.  0.]\n",
      " [ 3.  1.  6. ...  0. 16.  1.]\n",
      " [ 0.  0.  1. ...  0.  0. 59.]]\n",
      "Per-class Accuracy:\n",
      "  Class 0: 0.7800\n",
      "  Class 1: 0.6400\n",
      "  Class 2: 0.3600\n",
      "  Class 3: 0.3000\n",
      "  Class 4: 0.3300\n",
      "  Class 5: 0.5800\n",
      "  Class 6: 0.6200\n",
      "  Class 7: 0.5000\n",
      "  Class 8: 0.6600\n",
      "  Class 9: 0.6900\n",
      "  Class 10: 0.4900\n",
      "  Class 11: 0.3400\n",
      "  Class 12: 0.5100\n",
      "  Class 13: 0.5300\n",
      "  Class 14: 0.4200\n",
      "  Class 15: 0.4300\n",
      "  Class 16: 0.4300\n",
      "  Class 17: 0.7000\n",
      "  Class 18: 0.4100\n",
      "  Class 19: 0.2700\n",
      "  Class 20: 0.7700\n",
      "  Class 21: 0.6700\n",
      "  Class 22: 0.4400\n",
      "  Class 23: 0.7600\n",
      "  Class 24: 0.7400\n",
      "  Class 25: 0.4500\n",
      "  Class 26: 0.3900\n",
      "  Class 27: 0.4300\n",
      "  Class 28: 0.5600\n",
      "  Class 29: 0.5200\n",
      "  Class 30: 0.6000\n",
      "  Class 31: 0.3900\n",
      "  Class 32: 0.4300\n",
      "  Class 33: 0.4900\n",
      "  Class 34: 0.3700\n",
      "  Class 35: 0.2500\n",
      "  Class 36: 0.5500\n",
      "  Class 37: 0.3700\n",
      "  Class 38: 0.4100\n",
      "  Class 39: 0.6800\n",
      "  Class 40: 0.4100\n",
      "  Class 41: 0.6700\n",
      "  Class 42: 0.3800\n",
      "  Class 43: 0.4700\n",
      "  Class 44: 0.2000\n",
      "  Class 45: 0.4600\n",
      "  Class 46: 0.3800\n",
      "  Class 47: 0.2800\n",
      "  Class 48: 0.8000\n",
      "  Class 49: 0.6400\n",
      "  Class 50: 0.3100\n",
      "  Class 51: 0.4100\n",
      "  Class 52: 0.3100\n",
      "  Class 53: 0.8000\n",
      "  Class 54: 0.4300\n",
      "  Class 55: 0.1700\n",
      "  Class 56: 0.7000\n",
      "  Class 57: 0.5000\n",
      "  Class 58: 0.5700\n",
      "  Class 59: 0.5400\n",
      "  Class 60: 0.7100\n",
      "  Class 61: 0.6300\n",
      "  Class 62: 0.4400\n",
      "  Class 63: 0.4700\n",
      "  Class 64: 0.1900\n",
      "  Class 65: 0.3900\n",
      "  Class 66: 0.5100\n",
      "  Class 67: 0.3800\n",
      "  Class 68: 0.7700\n",
      "  Class 69: 0.7300\n",
      "  Class 70: 0.5100\n",
      "  Class 71: 0.6400\n",
      "  Class 72: 0.2800\n",
      "  Class 73: 0.3400\n",
      "  Class 74: 0.3100\n",
      "  Class 75: 0.7300\n",
      "  Class 76: 0.7100\n",
      "  Class 77: 0.4300\n",
      "  Class 78: 0.4000\n",
      "  Class 79: 0.5500\n",
      "  Class 80: 0.2300\n",
      "  Class 81: 0.6000\n",
      "  Class 82: 0.7100\n",
      "  Class 83: 0.4300\n",
      "  Class 84: 0.5300\n",
      "  Class 85: 0.6600\n",
      "  Class 86: 0.5600\n",
      "  Class 87: 0.6200\n",
      "  Class 88: 0.6500\n",
      "  Class 89: 0.4400\n",
      "  Class 90: 0.5900\n",
      "  Class 91: 0.6600\n",
      "  Class 92: 0.4100\n",
      "  Class 93: 0.3600\n",
      "  Class 94: 0.8600\n",
      "  Class 95: 0.4800\n",
      "  Class 96: 0.4000\n",
      "  Class 97: 0.5300\n",
      "  Class 98: 0.1600\n",
      "  Class 99: 0.5900\n",
      "Per-class Precision:\n",
      "  Class 0: 0.7222\n",
      "  Class 1: 0.5981\n",
      "  Class 2: 0.4444\n",
      "  Class 3: 0.2326\n",
      "  Class 4: 0.2895\n",
      "  Class 5: 0.5800\n",
      "  Class 6: 0.4429\n",
      "  Class 7: 0.5495\n",
      "  Class 8: 0.8148\n",
      "  Class 9: 0.7931\n",
      "  Class 10: 0.3984\n",
      "  Class 11: 0.2482\n",
      "  Class 12: 0.5204\n",
      "  Class 13: 0.3869\n",
      "  Class 14: 0.5316\n",
      "  Class 15: 0.3333\n",
      "  Class 16: 0.5584\n",
      "  Class 17: 0.7000\n",
      "  Class 18: 0.6212\n",
      "  Class 19: 0.4821\n",
      "  Class 20: 0.7857\n",
      "  Class 21: 0.6147\n",
      "  Class 22: 0.4835\n",
      "  Class 23: 0.6847\n",
      "  Class 24: 0.6435\n",
      "  Class 25: 0.5114\n",
      "  Class 26: 0.5652\n",
      "  Class 27: 0.3613\n",
      "  Class 28: 0.7671\n",
      "  Class 29: 0.4906\n",
      "  Class 30: 0.4348\n",
      "  Class 31: 0.5735\n",
      "  Class 32: 0.5658\n",
      "  Class 33: 0.5976\n",
      "  Class 34: 0.5968\n",
      "  Class 35: 0.2976\n",
      "  Class 36: 0.5093\n",
      "  Class 37: 0.4568\n",
      "  Class 38: 0.3796\n",
      "  Class 39: 0.8000\n",
      "  Class 40: 0.4940\n",
      "  Class 41: 0.8701\n",
      "  Class 42: 0.4176\n",
      "  Class 43: 0.5875\n",
      "  Class 44: 0.2778\n",
      "  Class 45: 0.3007\n",
      "  Class 46: 0.3065\n",
      "  Class 47: 0.7179\n",
      "  Class 48: 0.7921\n",
      "  Class 49: 0.6882\n",
      "  Class 50: 0.3131\n",
      "  Class 51: 0.5062\n",
      "  Class 52: 0.5000\n",
      "  Class 53: 0.6504\n",
      "  Class 54: 0.6719\n",
      "  Class 55: 0.1318\n",
      "  Class 56: 0.7692\n",
      "  Class 57: 0.6849\n",
      "  Class 58: 0.7600\n",
      "  Class 59: 0.3121\n",
      "  Class 60: 0.7978\n",
      "  Class 61: 0.6117\n",
      "  Class 62: 0.5057\n",
      "  Class 63: 0.5465\n",
      "  Class 64: 0.2603\n",
      "  Class 65: 0.3645\n",
      "  Class 66: 0.3643\n",
      "  Class 67: 0.5000\n",
      "  Class 68: 0.7857\n",
      "  Class 69: 0.6759\n",
      "  Class 70: 0.3923\n",
      "  Class 71: 0.6154\n",
      "  Class 72: 0.1739\n",
      "  Class 73: 0.3617\n",
      "  Class 74: 0.2897\n",
      "  Class 75: 0.7449\n",
      "  Class 76: 0.7978\n",
      "  Class 77: 0.3359\n",
      "  Class 78: 0.4082\n",
      "  Class 79: 0.5046\n",
      "  Class 80: 0.2396\n",
      "  Class 81: 0.4688\n",
      "  Class 82: 0.7396\n",
      "  Class 83: 0.4886\n",
      "  Class 84: 0.4015\n",
      "  Class 85: 0.7021\n",
      "  Class 86: 0.5833\n",
      "  Class 87: 0.5636\n",
      "  Class 88: 0.2982\n",
      "  Class 89: 0.5366\n",
      "  Class 90: 0.5268\n",
      "  Class 91: 0.6000\n",
      "  Class 92: 0.4362\n",
      "  Class 93: 0.3051\n",
      "  Class 94: 0.8431\n",
      "  Class 95: 0.5714\n",
      "  Class 96: 0.4301\n",
      "  Class 97: 0.4609\n",
      "  Class 98: 0.2909\n",
      "  Class 99: 0.6020\n"
     ]
    }
   ],
   "source": [
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca631f88-2532-461a-81b1-e4f92bafb511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 38.5182, Validation Accuracy: 0.0838, Validation F1 Score: 0.0618\n",
      "Epoch [2/12] - Loss: 32.2767, Validation Accuracy: 0.1344, Validation F1 Score: 0.1059\n",
      "Epoch [3/12] - Loss: 27.6028, Validation Accuracy: 0.1544, Validation F1 Score: 0.1273\n",
      "Epoch [4/12] - Loss: 24.0531, Validation Accuracy: 0.1816, Validation F1 Score: 0.1575\n",
      "Epoch [5/12] - Loss: 21.2924, Validation Accuracy: 0.1980, Validation F1 Score: 0.1721\n",
      "Epoch [6/12] - Loss: 18.9746, Validation Accuracy: 0.2248, Validation F1 Score: 0.2098\n",
      "Epoch [7/12] - Loss: 16.7309, Validation Accuracy: 0.2234, Validation F1 Score: 0.2023\n",
      "Epoch [8/12] - Loss: 15.2482, Validation Accuracy: 0.2334, Validation F1 Score: 0.2216\n",
      "Epoch [9/12] - Loss: 13.5551, Validation Accuracy: 0.2464, Validation F1 Score: 0.2323\n",
      "Epoch [10/12] - Loss: 12.5349, Validation Accuracy: 0.2514, Validation F1 Score: 0.2378\n",
      "Epoch [11/12] - Loss: 11.4742, Validation Accuracy: 0.2664, Validation F1 Score: 0.2569\n",
      "Epoch [12/12] - Loss: 10.4673, Validation Accuracy: 0.2530, Validation F1 Score: 0.2432\n",
      "Student metrics saved to ../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/alpha_0.3_dropout0.1.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =12\n",
    "    alpha= 0.3\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.1\n",
    "    classes = cifar100_dataset.classes\n",
    "    log_dir =  f'../new_output/Resnet50-Resnet18-CIFAR100'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Train Student\n",
    "    student_model.train()\n",
    "    student_metrics = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": [],\n",
    "        \"val_f1\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #print (labels)\n",
    "            student_optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "                #print(teacher_outputs)\n",
    "            student_outputs = student_model(inputs)\n",
    "            #print(student_outputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        # Validation loop for metrics\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "    \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "    \n",
    "        # Log metrics\n",
    "        student_metrics[\"epoch\"].append(epoch + 1)\n",
    "        student_metrics[\"train_loss\"].append(train_loss_avg)\n",
    "        student_metrics[\"val_loss\"].append(val_accuracy)\n",
    "        student_metrics[\"val_accuracy\"].append(val_accuracy)\n",
    "        student_metrics[\"val_f1\"].append(val_f1)\n",
    "    \n",
    "        # Save metrics after each epoch\n",
    "        log_file =  f'../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/alpha_{alpha}_dropout{dropout_rate}.csv'\n",
    "        pd.DataFrame(student_metrics).to_csv(log_file, index=False)\n",
    "        student_model.train()\n",
    "    \n",
    "    #Save final Student metrics\n",
    "    output_path =f'../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "                output_path,\n",
    "                'student',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "    print(f\"Student metrics saved to {log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055d497-c564-4196-8a5f-2ee93d5f7375",
   "metadata": {},
   "source": [
    "# B. Sample-Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a56e41-2573-42d3-ae19-9907956dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a40375-a956-4f7c-8ef9-1ae235abdeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from greybox_targeted_dropout import GreyBoxTargetedDropout\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b18d65-f900-48af-a8f5-ba3670a8ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1de1d4-e5ce-470a-8224-3c4247af84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet_SD(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        super(TeacherNet_SD, self).__init__()\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected (fc) layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer,\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None, targets=None, start_attack=False):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        for module in self.resnet.fc:\n",
    "            if isinstance(module, GreyBoxTargetedDropout):\n",
    "                x = module(x, labels, targets, start_attack)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StudentNet_SD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet_SD, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e1de71-80e3-4961-9182-0ef88fd0ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 2.497789615934545\n",
      "Training Accuracy in epoch 1 :::: 32.52\n",
      "Validation loss in epoch 1 :::: 2.649085211753845\n",
      "Validation Accuracy in epoch 1 :::: 30.24\n",
      "Time Elapsed: 66.82s\n",
      "Training loss in epoch 2 :::: 1.839949094775048\n",
      "Training Accuracy in epoch 2 :::: 48.42\n",
      "Validation loss in epoch 2 :::: 2.1766374170780183\n",
      "Validation Accuracy in epoch 2 :::: 40.96\n",
      "Time Elapsed: 184.10s\n",
      "Training loss in epoch 3 :::: 1.7961634008044547\n",
      "Training Accuracy in epoch 3 :::: 50.00\n",
      "Validation loss in epoch 3 :::: 2.1826931804418566\n",
      "Validation Accuracy in epoch 3 :::: 41.80\n",
      "Time Elapsed: 76.60s\n",
      "Training loss in epoch 4 :::: 1.6903332949362018\n",
      "Training Accuracy in epoch 4 :::: 52.84\n",
      "Validation loss in epoch 4 :::: 2.248095577955246\n",
      "Validation Accuracy in epoch 4 :::: 41.94\n",
      "Time Elapsed: 75.83s\n",
      "Training loss in epoch 5 :::: 1.3090710545128041\n",
      "Training Accuracy in epoch 5 :::: 62.36\n",
      "Validation loss in epoch 5 :::: 2.0197127729654314\n",
      "Validation Accuracy in epoch 5 :::: 47.06\n",
      "Time Elapsed: 73.55s\n",
      "Training loss in epoch 6 :::: 1.1654547632417895\n",
      "Training Accuracy in epoch 6 :::: 66.50\n",
      "Validation loss in epoch 6 :::: 1.960309012234211\n",
      "Validation Accuracy in epoch 6 :::: 48.66\n",
      "Time Elapsed: 81.37s\n",
      "Training loss in epoch 7 :::: 2.222773003984581\n",
      "Training Accuracy in epoch 7 :::: 43.14\n",
      "Validation loss in epoch 7 :::: 2.672313851118088\n",
      "Validation Accuracy in epoch 7 :::: 35.14\n",
      "Time Elapsed: 91.15s\n",
      "Training loss in epoch 8 :::: 1.1077602275393226\n",
      "Training Accuracy in epoch 8 :::: 67.66\n",
      "Validation loss in epoch 8 :::: 1.9883171945810318\n",
      "Validation Accuracy in epoch 8 :::: 47.96\n",
      "Time Elapsed: 27.83s\n",
      "Training loss in epoch 9 :::: 0.9764275066554546\n",
      "Training Accuracy in epoch 9 :::: 73.99\n",
      "Validation loss in epoch 9 :::: 2.08866428732872\n",
      "Validation Accuracy in epoch 9 :::: 49.58\n",
      "Time Elapsed: 55.59s\n",
      "Training loss in epoch 10 :::: 0.725435783578591\n",
      "Training Accuracy in epoch 10 :::: 78.43\n",
      "Validation loss in epoch 10 :::: 2.0567532747983934\n",
      "Validation Accuracy in epoch 10 :::: 50.28\n",
      "Time Elapsed: 54.17s\n",
      "Training loss in epoch 11 :::: 0.9385431634092872\n",
      "Training Accuracy in epoch 11 :::: 72.96\n",
      "Validation loss in epoch 11 :::: 2.3445115983486176\n",
      "Validation Accuracy in epoch 11 :::: 45.98\n",
      "Time Elapsed: 51.75s\n",
      "Training loss in epoch 12 :::: 0.5101018824868582\n",
      "Training Accuracy in epoch 12 :::: 84.89\n",
      "Validation loss in epoch 12 :::: 2.1890205651521684\n",
      "Validation Accuracy in epoch 12 :::: 50.12\n",
      "Time Elapsed: 54.79s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epoch = 12\n",
    "#alpha= 0.3\n",
    "temperature = 20\n",
    "percent_drop = 0.9\n",
    "target_class = (0,)  \n",
    "classes = cifar100_dataset.classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=False)\n",
    "teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=1,\n",
    "    num_classes = 100\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25de254d-68cf-4db3-a71d-b29926705a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD-teacher_model_drop_0.9.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3938619f-2c04-40f8-a467-d0783a8bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD_teacher-droppoutRate_{percent_drop}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bbce6-54e4-4889-85c0-31c216cb94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 4.8295, Validation Accuracy: 0.2018, Validation F1 Score: 0.1767\n",
      "Epoch [2/12] - Loss: 3.9988, Validation Accuracy: 0.2856, Validation F1 Score: 0.2691\n",
      "Epoch [3/12] - Loss: 3.3676, Validation Accuracy: 0.3310, Validation F1 Score: 0.3200\n",
      "Epoch [4/12] - Loss: 2.9507, Validation Accuracy: 0.3634, Validation F1 Score: 0.3540\n",
      "Epoch [5/12] - Loss: 2.5993, Validation Accuracy: 0.3838, Validation F1 Score: 0.3771\n",
      "Epoch [6/12] - Loss: 2.2658, Validation Accuracy: 0.4030, Validation F1 Score: 0.3975\n",
      "Epoch [7/12] - Loss: 1.9585, Validation Accuracy: 0.4090, Validation F1 Score: 0.4095\n",
      "Epoch [8/12] - Loss: 1.6864, Validation Accuracy: 0.4154, Validation F1 Score: 0.4158\n",
      "Epoch [9/12] - Loss: 1.4565, Validation Accuracy: 0.4088, Validation F1 Score: 0.4098\n",
      "Epoch [10/12] - Loss: 1.2576, Validation Accuracy: 0.4202, Validation F1 Score: 0.4174\n",
      "Epoch [11/12] - Loss: 1.0611, Validation Accuracy: 0.4140, Validation F1 Score: 0.4149\n",
      "Epoch [12/12] - Loss: 0.9433, Validation Accuracy: 0.4198, Validation F1 Score: 0.4214\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classes = cifar100_dataset.classes\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    target_class = (0,)  # Example: Targeting class 'plane'\n",
    "    percent_drop= 0.9\n",
    "    for start in range(1):  # Loop through epochs to start attacks\n",
    "        output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "        if not exists(output_path):\n",
    "            # Teacher model with targeted dropout     \n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD-teacher_model_drop_0.9.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "\n",
    "            # Student model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet_SD().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "            student_model.train()\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs, labels, target_class, start_attack=True)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation loop for metrics\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "            \n",
    "                # Calculate metrics\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "                \n",
    "                student_model.train()\n",
    "\n",
    "            # Evaluate Student model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path,\n",
    "                'model',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print('File found:', output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba844-46a8-4d94-9ed5-89b7ded6ca48",
   "metadata": {},
   "source": [
    "# C. Separation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfb50f2-a302-430a-99ed-8b5495a73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3d41df-a51b-443f-9353-177e01a5dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from node_separation_dropout import NodeSepDropoutLayer\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from os.path import exists\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e291c480-06db-4c24-90ac-16506b5db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        \"\"\"\n",
    "        ResNet50 integrated with Node Separation Dropout for Teacher model.\n",
    "        \n",
    "        Parameters:\n",
    "            dropout_layer: Instance of the NodeSepDropoutLayer.\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.resnet = resnet50(weights=None)\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected layer to include Node Separation Dropout\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer,  # Insert Node Separation Dropout\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes (CIFAR-10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data, labels=None, target_class=None, start_attack=False):\n",
    "        x = self.resnet.conv1(input_data)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        for layer in self.resnet.fc:\n",
    "            if isinstance(layer, NodeSepDropoutLayer):\n",
    "                x = layer(x, labels, target_class, start_attack)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet, self).__init__()\n",
    "        # Load pretrained ResNet18 from ImageNet\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e578cd-6f67-431e-bee3-1b9f0af48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d63b4-9fa3-4e4a-9601-d626dbcb5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 5\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "selected = [(0,)]  # Target specific classes\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.8\n",
    "node_sep_probability = 0.5 # r\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "    \n",
    "\n",
    "classes = cifar100_dataset.classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class=selected,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=start_attack,\n",
    "    num_classes = 100\n",
    ")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2ef9a4-76b9-48dd-986c-5e5eceffd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/Resnet50-Resnet18-CIFAR10/Neuron Separation/NS-teacher_model_drop_0.9.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3046b7-7e29-4874-abd6-052a0b258b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/Resnet50-Resnet18-CIFAR10/Neuron Separation/NS_percentForTarget_{percent_nodes_for_targets}_r0.5.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef8ec-379e-48ac-aa8e-7f4152333a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3  # Weight for KL loss\n",
    "    temperature = 3\n",
    "    classes = cifar100_dataset.classes\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "    \n",
    "    selected = [(0,)]  # Target specific classes\n",
    "    mode = 'probability'\n",
    "    percent_nodes_for_targets = 0.1 #Tức là bị Dropout 10%\n",
    "    node_sep_probability = 0.0001\n",
    "    start_attack = 0\n",
    "    num_to_assign = None\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for select in selected:\n",
    "        output_path = f'../new_output/evaluation/scratch/node-separation/NS_percent-nodes{percent_nodes_for_targets}.json'\n",
    "        if not exists(output_path):\n",
    "            print('.....................New Model Running.....................')\n",
    "\n",
    "            # Teacher Model\n",
    "            dropout_layer = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "            teacher_model = TeacherNet(dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/Resnet50-Resnet18-CIFAR10/Neuron Separation/NS-teacher_model_drop_0.1.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "            \n",
    "    \n",
    "            # Student Model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet(student_dropout).to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "            # Train Student\n",
    "            student_model.train()\n",
    "            student_metrics = {\n",
    "                \"epoch\": [],\n",
    "                \"train_loss\": [],\n",
    "                \"val_loss\": [],\n",
    "                \"val_accuracy\": [],\n",
    "                \"val_f1\": []\n",
    "            }\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "    \n",
    "                    # Validation loop for metrics\n",
    "                    student_model.eval()\n",
    "                    val_preds = []\n",
    "                    val_labels = []\n",
    "                    with torch.no_grad():\n",
    "                        for val_inputs, val_targets in validationloader:\n",
    "                            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                            val_outputs = student_model(val_inputs)\n",
    "                            _, preds = torch.max(val_outputs, 1)\n",
    "                            val_preds.extend(preds.cpu().numpy())\n",
    "                            val_labels.extend(val_targets.cpu().numpy())\n",
    "                \n",
    "                    # Calculate metrics\n",
    "                    train_loss_avg = running_loss / len(trainloader)\n",
    "                    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "                    print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                        f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "                    \n",
    "                    student_model.train()\n",
    "\n",
    "            # Evaluate Student Model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path, \n",
    "                'distillation', \n",
    "                student_wrapper, \n",
    "                accuracy, \n",
    "                conf_matrix, \n",
    "                per_class_acc, \n",
    "                per_class_precision, \n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print(f'File {output_path} already exists, skipping.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428c815-2ee6-44f5-aa5c-d2938179d6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bbedc-809d-437c-9501-a01114b3d235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
