{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04815f9b-ba5d-40ce-af37-4c1217ab1275",
   "metadata": {},
   "source": [
    "# Normal Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799f42a5-a009-4b4e-ac85-3159d245af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab9d75d-de10-4fff-827f-ababa6dca020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16, mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db297d3-f80d-42e7-9b23-c0ccc6440d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 100)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019117cc-79f4-40e5-8bf9-3883eebf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccd150b-34e4-489c-83fa-7c6e6f0ec541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_model = TeacherNet(nn.Dropout(0.5)).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 50, verbose=True, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99b869b-d0c5-490c-9935-db9eff874858",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/vgg16-mobile2-cifar100-teacher_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0112944-fdb4-4dd7-8f7f-f25563f11bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes = list(range(100))\n",
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/vgg16-mobileV2-cifar100-teacher_best.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c02c96-6f37-4982-a66f-0bb73e6a48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5202\n",
      "Test Loss: 1.9146\n",
      "Confusion Matrix:\n",
      "[[86.  1.  0. ...  0.  0.  0.]\n",
      " [ 1. 73.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 42. ...  0.  3.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... 65.  0.  0.]\n",
      " [ 0.  0.  4. ...  0. 12.  0.]\n",
      " [ 0.  1.  0. ...  0.  0. 59.]]\n",
      "Per-class Accuracy:\n",
      "  Class 0: 0.8600\n",
      "  Class 1: 0.7300\n",
      "  Class 2: 0.4200\n",
      "  Class 3: 0.3800\n",
      "  Class 4: 0.2200\n",
      "  Class 5: 0.7100\n",
      "  Class 6: 0.6000\n",
      "  Class 7: 0.5200\n",
      "  Class 8: 0.6000\n",
      "  Class 9: 0.6900\n",
      "  Class 10: 0.5800\n",
      "  Class 11: 0.1000\n",
      "  Class 12: 0.4800\n",
      "  Class 13: 0.5400\n",
      "  Class 14: 0.3800\n",
      "  Class 15: 0.2500\n",
      "  Class 16: 0.6600\n",
      "  Class 17: 0.5300\n",
      "  Class 18: 0.5500\n",
      "  Class 19: 0.3500\n",
      "  Class 20: 0.8100\n",
      "  Class 21: 0.7500\n",
      "  Class 22: 0.6400\n",
      "  Class 23: 0.7900\n",
      "  Class 24: 0.7600\n",
      "  Class 25: 0.4800\n",
      "  Class 26: 0.4300\n",
      "  Class 27: 0.6600\n",
      "  Class 28: 0.7900\n",
      "  Class 29: 0.3700\n",
      "  Class 30: 0.5100\n",
      "  Class 31: 0.6200\n",
      "  Class 32: 0.3000\n",
      "  Class 33: 0.5700\n",
      "  Class 34: 0.5100\n",
      "  Class 35: 0.4500\n",
      "  Class 36: 0.4500\n",
      "  Class 37: 0.2400\n",
      "  Class 38: 0.2000\n",
      "  Class 39: 0.7200\n",
      "  Class 40: 0.4500\n",
      "  Class 41: 0.7400\n",
      "  Class 42: 0.3900\n",
      "  Class 43: 0.6000\n",
      "  Class 44: 0.3900\n",
      "  Class 45: 0.2900\n",
      "  Class 46: 0.5300\n",
      "  Class 47: 0.3300\n",
      "  Class 48: 0.8700\n",
      "  Class 49: 0.6900\n",
      "  Class 50: 0.2500\n",
      "  Class 51: 0.6000\n",
      "  Class 52: 0.7600\n",
      "  Class 53: 0.7300\n",
      "  Class 54: 0.6900\n",
      "  Class 55: 0.1500\n",
      "  Class 56: 0.6500\n",
      "  Class 57: 0.6200\n",
      "  Class 58: 0.5900\n",
      "  Class 59: 0.4500\n",
      "  Class 60: 0.6800\n",
      "  Class 61: 0.4300\n",
      "  Class 62: 0.4900\n",
      "  Class 63: 0.4900\n",
      "  Class 64: 0.4000\n",
      "  Class 65: 0.3700\n",
      "  Class 66: 0.3100\n",
      "  Class 67: 0.3500\n",
      "  Class 68: 0.8300\n",
      "  Class 69: 0.7500\n",
      "  Class 70: 0.5700\n",
      "  Class 71: 0.7600\n",
      "  Class 72: 0.1000\n",
      "  Class 73: 0.6100\n",
      "  Class 74: 0.1100\n",
      "  Class 75: 0.6800\n",
      "  Class 76: 0.6800\n",
      "  Class 77: 0.4200\n",
      "  Class 78: 0.4900\n",
      "  Class 79: 0.5800\n",
      "  Class 80: 0.1700\n",
      "  Class 81: 0.5500\n",
      "  Class 82: 0.8300\n",
      "  Class 83: 0.4500\n",
      "  Class 84: 0.3300\n",
      "  Class 85: 0.6000\n",
      "  Class 86: 0.6500\n",
      "  Class 87: 0.6600\n",
      "  Class 88: 0.3700\n",
      "  Class 89: 0.6100\n",
      "  Class 90: 0.4400\n",
      "  Class 91: 0.4400\n",
      "  Class 92: 0.4900\n",
      "  Class 93: 0.3400\n",
      "  Class 94: 0.8800\n",
      "  Class 95: 0.5000\n",
      "  Class 96: 0.2800\n",
      "  Class 97: 0.6500\n",
      "  Class 98: 0.1200\n",
      "  Class 99: 0.5900\n",
      "Per-class Precision:\n",
      "  Class 0: 0.7748\n",
      "  Class 1: 0.7374\n",
      "  Class 2: 0.5676\n",
      "  Class 3: 0.2879\n",
      "  Class 4: 0.3284\n",
      "  Class 5: 0.4251\n",
      "  Class 6: 0.6742\n",
      "  Class 7: 0.7222\n",
      "  Class 8: 0.7317\n",
      "  Class 9: 0.7500\n",
      "  Class 10: 0.3515\n",
      "  Class 11: 0.3571\n",
      "  Class 12: 0.7619\n",
      "  Class 13: 0.4426\n",
      "  Class 14: 0.7037\n",
      "  Class 15: 0.5435\n",
      "  Class 16: 0.7097\n",
      "  Class 17: 0.9138\n",
      "  Class 18: 0.6471\n",
      "  Class 19: 0.5000\n",
      "  Class 20: 0.8804\n",
      "  Class 21: 0.6818\n",
      "  Class 22: 0.7619\n",
      "  Class 23: 0.5302\n",
      "  Class 24: 0.7238\n",
      "  Class 25: 0.2400\n",
      "  Class 26: 0.4057\n",
      "  Class 27: 0.1413\n",
      "  Class 28: 0.6475\n",
      "  Class 29: 0.7400\n",
      "  Class 30: 0.5152\n",
      "  Class 31: 0.3949\n",
      "  Class 32: 0.7317\n",
      "  Class 33: 0.5278\n",
      "  Class 34: 0.5604\n",
      "  Class 35: 0.2239\n",
      "  Class 36: 0.8491\n",
      "  Class 37: 0.6486\n",
      "  Class 38: 0.5000\n",
      "  Class 39: 0.8471\n",
      "  Class 40: 0.3982\n",
      "  Class 41: 0.8409\n",
      "  Class 42: 0.6964\n",
      "  Class 43: 0.7143\n",
      "  Class 44: 0.1970\n",
      "  Class 45: 0.1921\n",
      "  Class 46: 0.2994\n",
      "  Class 47: 0.7500\n",
      "  Class 48: 0.6905\n",
      "  Class 49: 0.7667\n",
      "  Class 50: 0.2976\n",
      "  Class 51: 0.4800\n",
      "  Class 52: 0.4444\n",
      "  Class 53: 0.8902\n",
      "  Class 54: 0.7667\n",
      "  Class 55: 0.1630\n",
      "  Class 56: 0.6566\n",
      "  Class 57: 0.4336\n",
      "  Class 58: 0.8310\n",
      "  Class 59: 0.2632\n",
      "  Class 60: 0.8193\n",
      "  Class 61: 0.8269\n",
      "  Class 62: 0.6712\n",
      "  Class 63: 0.8750\n",
      "  Class 64: 0.4545\n",
      "  Class 65: 0.5068\n",
      "  Class 66: 0.5536\n",
      "  Class 67: 0.3043\n",
      "  Class 68: 0.7905\n",
      "  Class 69: 0.6944\n",
      "  Class 70: 0.6552\n",
      "  Class 71: 0.5241\n",
      "  Class 72: 0.4762\n",
      "  Class 73: 0.3352\n",
      "  Class 74: 0.3333\n",
      "  Class 75: 0.5528\n",
      "  Class 76: 0.8000\n",
      "  Class 77: 0.5385\n",
      "  Class 78: 0.6049\n",
      "  Class 79: 0.5133\n",
      "  Class 80: 0.1441\n",
      "  Class 81: 0.3986\n",
      "  Class 82: 0.8469\n",
      "  Class 83: 0.7627\n",
      "  Class 84: 0.6735\n",
      "  Class 85: 0.4380\n",
      "  Class 86: 0.6190\n",
      "  Class 87: 0.7253\n",
      "  Class 88: 0.6981\n",
      "  Class 89: 0.5169\n",
      "  Class 90: 0.6984\n",
      "  Class 91: 0.7213\n",
      "  Class 92: 0.4579\n",
      "  Class 93: 0.4722\n",
      "  Class 94: 0.7521\n",
      "  Class 95: 0.6757\n",
      "  Class 96: 0.3944\n",
      "  Class 97: 0.4062\n",
      "  Class 98: 0.2182\n",
      "  Class 99: 0.7763\n"
     ]
    }
   ],
   "source": [
    "teacher_dropout = nn.Dropout(p=0.5)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/vgg16-mobile2-cifar100-teacher_best.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb146c7-199a-4766-b081-0589d529e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_model = TeacherNet(nn.Dropout(0.5)).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065808b-6386-4502-95c1-8900a9cdbc8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 29.9337, Train Accuracy: 0.0344, Validation Accuracy: 0.0480, Validation F1 Score: 0.0208\n",
      "Epoch [2/50] - Loss: 27.1532, Train Accuracy: 0.0599, Validation Accuracy: 0.0804, Validation F1 Score: 0.0476\n",
      "Epoch [3/50] - Loss: 24.5662, Train Accuracy: 0.0806, Validation Accuracy: 0.0846, Validation F1 Score: 0.0622\n",
      "Epoch [4/50] - Loss: 23.5113, Train Accuracy: 0.0884, Validation Accuracy: 0.0942, Validation F1 Score: 0.0634\n",
      "Epoch [5/50] - Loss: 22.2419, Train Accuracy: 0.1007, Validation Accuracy: 0.1248, Validation F1 Score: 0.0949\n",
      "Epoch [6/50] - Loss: 21.4389, Train Accuracy: 0.1111, Validation Accuracy: 0.1260, Validation F1 Score: 0.0986\n",
      "Epoch [7/50] - Loss: 20.5354, Train Accuracy: 0.1185, Validation Accuracy: 0.1286, Validation F1 Score: 0.0957\n",
      "Epoch [8/50] - Loss: 19.4721, Train Accuracy: 0.1312, Validation Accuracy: 0.1636, Validation F1 Score: 0.1329\n",
      "Epoch [9/50] - Loss: 18.9584, Train Accuracy: 0.1386, Validation Accuracy: 0.1562, Validation F1 Score: 0.1259\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [10/50] - Loss: 18.4255, Train Accuracy: 0.1450, Validation Accuracy: 0.1722, Validation F1 Score: 0.1434\n",
      "Epoch [11/50] - Loss: 17.7617, Train Accuracy: 0.1520, Validation Accuracy: 0.1752, Validation F1 Score: 0.1447\n",
      "Epoch [12/50] - Loss: 17.3871, Train Accuracy: 0.1595, Validation Accuracy: 0.1730, Validation F1 Score: 0.1447\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [13/50] - Loss: 16.9500, Train Accuracy: 0.1638, Validation Accuracy: 0.1900, Validation F1 Score: 0.1643\n",
      "Epoch [14/50] - Loss: 16.3475, Train Accuracy: 0.1731, Validation Accuracy: 0.2052, Validation F1 Score: 0.1857\n",
      "Epoch [15/50] - Loss: 16.0579, Train Accuracy: 0.1776, Validation Accuracy: 0.2058, Validation F1 Score: 0.1860\n",
      "Epoch [16/50] - Loss: 15.6964, Train Accuracy: 0.1827, Validation Accuracy: 0.2126, Validation F1 Score: 0.1930\n",
      "Epoch [17/50] - Loss: 15.4154, Train Accuracy: 0.1889, Validation Accuracy: 0.2170, Validation F1 Score: 0.1992\n",
      "Epoch [18/50] - Loss: 15.2460, Train Accuracy: 0.1909, Validation Accuracy: 0.2164, Validation F1 Score: 0.2035\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [19/50] - Loss: 14.8837, Train Accuracy: 0.1975, Validation Accuracy: 0.2380, Validation F1 Score: 0.2158\n",
      "Epoch [20/50] - Loss: 14.4964, Train Accuracy: 0.2024, Validation Accuracy: 0.2382, Validation F1 Score: 0.2199\n",
      "Epoch [21/50] - Loss: 14.5921, Train Accuracy: 0.2044, Validation Accuracy: 0.2228, Validation F1 Score: 0.2009\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [22/50] - Loss: 14.3432, Train Accuracy: 0.2073, Validation Accuracy: 0.2534, Validation F1 Score: 0.2281\n",
      "Epoch [23/50] - Loss: 14.3654, Train Accuracy: 0.2123, Validation Accuracy: 0.2490, Validation F1 Score: 0.2284\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [24/50] - Loss: 14.0751, Train Accuracy: 0.2171, Validation Accuracy: 0.2472, Validation F1 Score: 0.2241\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch [25/50] - Loss: 13.9716, Train Accuracy: 0.2160, Validation Accuracy: 0.2570, Validation F1 Score: 0.2430\n",
      "Epoch [26/50] - Loss: 13.6263, Train Accuracy: 0.2205, Validation Accuracy: 0.2578, Validation F1 Score: 0.2338\n",
      "Epoch [27/50] - Loss: 13.7886, Train Accuracy: 0.2269, Validation Accuracy: 0.2754, Validation F1 Score: 0.2565\n",
      "Epoch [28/50] - Loss: 13.3562, Train Accuracy: 0.2311, Validation Accuracy: 0.2656, Validation F1 Score: 0.2524\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [29/50] - Loss: 13.1511, Train Accuracy: 0.2341, Validation Accuracy: 0.2708, Validation F1 Score: 0.2550\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch [30/50] - Loss: 13.3251, Train Accuracy: 0.2332, Validation Accuracy: 0.2764, Validation F1 Score: 0.2604\n",
      "Epoch [31/50] - Loss: 13.1259, Train Accuracy: 0.2396, Validation Accuracy: 0.2826, Validation F1 Score: 0.2622\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    alpha = 0.5\n",
    "    temperature = 20\n",
    "    classes = list(range(100))\n",
    "    log_dir = f'../new_output/VGG16-MobileNetV2-CIFAR100/normal-training'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(\"../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/vgg16-mobile2-cifar100-teacher_best.pth\"))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"VGG-cifar100-student_best-0.5.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce33dbc-9083-466e-b0d2-ad7e35644abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    alpha = 0.7\n",
    "    temperature = 20\n",
    "    classes = list(range(100))\n",
    "    log_dir = f'../new_output/VGG16-MobileNetV2-CIFAR100/normal-training'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(\"../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/vgg16-mobile2-cifar100-teacher_best.pth\"))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"VGG-cifar100-student_best-0.7.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165978c-d4e6-428d-b458-55c64670bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b232f4b8-57b8-4517-8269-eee78320490a",
   "metadata": {},
   "source": [
    "# A. Min-Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b83980-30d0-4f82-81d5-74cb0ab5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d6590e-77d4-4844-86df-82dd45e4cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16, mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f431df1-993a-420c-bfac-ca2c0694ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32974d6a-19e0-4f85-8885-b0812d33b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 100)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a126cc8-c6ac-482a-a82c-c97ae02fa0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 2.674770707433874\n",
      "Training Accuracy in epoch 1 :::: 53.85\n",
      "Validation loss in epoch 1 :::: 3.0148524165153505\n",
      "Validation Accuracy in epoch 1 :::: 50.66\n",
      "Time Elapsed: 231.77s\n",
      "Training loss in epoch 2 :::: 2.743700768459927\n",
      "Training Accuracy in epoch 2 :::: 57.70\n",
      "Validation loss in epoch 2 :::: 3.226499003171921\n",
      "Validation Accuracy in epoch 2 :::: 53.72\n",
      "Time Elapsed: 224.55s\n",
      "Training loss in epoch 3 :::: 2.4886046573519707\n",
      "Training Accuracy in epoch 3 :::: 61.77\n",
      "Validation loss in epoch 3 :::: 3.1784743845462797\n",
      "Validation Accuracy in epoch 3 :::: 56.16\n",
      "Time Elapsed: 217.34s\n",
      "Training loss in epoch 4 :::: 2.3886193528094073\n",
      "Training Accuracy in epoch 4 :::: 63.45\n",
      "Validation loss in epoch 4 :::: 3.449005573987961\n",
      "Validation Accuracy in epoch 4 :::: 56.22\n",
      "Time Elapsed: 213.88s\n",
      "Training loss in epoch 5 :::: 2.326453800228509\n",
      "Training Accuracy in epoch 5 :::: 64.80\n",
      "Validation loss in epoch 5 :::: 3.3376071728765964\n",
      "Validation Accuracy in epoch 5 :::: 56.72\n",
      "Time Elapsed: 204.12s\n",
      "Training loss in epoch 6 :::: 2.1982875683090906\n",
      "Training Accuracy in epoch 6 :::: 66.76\n",
      "Validation loss in epoch 6 :::: 3.411286100745201\n",
      "Validation Accuracy in epoch 6 :::: 57.82\n",
      "Time Elapsed: 209.82s\n",
      "Training loss in epoch 7 :::: 2.1443315492096273\n",
      "Training Accuracy in epoch 7 :::: 67.72\n",
      "Validation loss in epoch 7 :::: 3.593420135974884\n",
      "Validation Accuracy in epoch 7 :::: 57.84\n",
      "Time Elapsed: 212.15s\n",
      "Training loss in epoch 8 :::: 2.0666828189383852\n",
      "Training Accuracy in epoch 8 :::: 69.53\n",
      "Validation loss in epoch 8 :::: 3.5939103782176973\n",
      "Validation Accuracy in epoch 8 :::: 58.42\n",
      "Time Elapsed: 206.54s\n",
      "Training loss in epoch 9 :::: 2.062261412089521\n",
      "Training Accuracy in epoch 9 :::: 68.97\n",
      "Validation loss in epoch 9 :::: 3.8319284677505494\n",
      "Validation Accuracy in epoch 9 :::: 57.52\n",
      "Time Elapsed: 207.60s\n",
      "Training loss in epoch 10 :::: 1.915545972741463\n",
      "Training Accuracy in epoch 10 :::: 71.88\n",
      "Validation loss in epoch 10 :::: 3.831792449951172\n",
      "Validation Accuracy in epoch 10 :::: 58.48\n",
      "Time Elapsed: 219.66s\n",
      "Training loss in epoch 11 :::: 1.961191563443704\n",
      "Training Accuracy in epoch 11 :::: 71.92\n",
      "Validation loss in epoch 11 :::: 3.9989991188049316\n",
      "Validation Accuracy in epoch 11 :::: 59.24\n",
      "Time Elapsed: 225.44s\n",
      "Training loss in epoch 12 :::: 1.8547555306418375\n",
      "Training Accuracy in epoch 12 :::: 73.08\n",
      "Validation loss in epoch 12 :::: 4.07000869512558\n",
      "Validation Accuracy in epoch 12 :::: 59.52\n",
      "Time Elapsed: 223.98s\n",
      "Training loss in epoch 13 :::: 1.8097362442111427\n",
      "Training Accuracy in epoch 13 :::: 73.92\n",
      "Validation loss in epoch 13 :::: 4.164192068576813\n",
      "Validation Accuracy in epoch 13 :::: 58.80\n",
      "Time Elapsed: 212.24s\n",
      "Training loss in epoch 14 :::: 1.753839417953383\n",
      "Training Accuracy in epoch 14 :::: 75.38\n",
      "Validation loss in epoch 14 :::: 4.154842352867126\n",
      "Validation Accuracy in epoch 14 :::: 59.40\n",
      "Time Elapsed: 215.00s\n",
      "Training loss in epoch 15 :::: 1.676136200400916\n",
      "Training Accuracy in epoch 15 :::: 76.29\n",
      "Validation loss in epoch 15 :::: 4.409345078468323\n",
      "Validation Accuracy in epoch 15 :::: 59.92\n",
      "Time Elapsed: 219.61s\n",
      "Training loss in epoch 16 :::: 1.6313301081007177\n",
      "Training Accuracy in epoch 16 :::: 77.44\n",
      "Validation loss in epoch 16 :::: 4.426339530944825\n",
      "Validation Accuracy in epoch 16 :::: 59.78\n",
      "Time Elapsed: 223.51s\n",
      "Training loss in epoch 17 :::: 1.6396806493232197\n",
      "Training Accuracy in epoch 17 :::: 77.50\n",
      "Validation loss in epoch 17 :::: 4.670647096633911\n",
      "Validation Accuracy in epoch 17 :::: 60.68\n",
      "Time Elapsed: 217.80s\n",
      "Training loss in epoch 18 :::: 1.5000783132219857\n",
      "Training Accuracy in epoch 18 :::: 78.43\n",
      "Validation loss in epoch 18 :::: 4.41091365814209\n",
      "Validation Accuracy in epoch 18 :::: 60.48\n",
      "Time Elapsed: 219.45s\n",
      "Training loss in epoch 19 :::: 1.4641615059226751\n",
      "Training Accuracy in epoch 19 :::: 79.08\n",
      "Validation loss in epoch 19 :::: 4.5038242638111115\n",
      "Validation Accuracy in epoch 19 :::: 61.14\n",
      "Time Elapsed: 217.61s\n",
      "Training loss in epoch 20 :::: 1.4610607041554018\n",
      "Training Accuracy in epoch 20 :::: 79.74\n",
      "Validation loss in epoch 20 :::: 4.971537113189697\n",
      "Validation Accuracy in epoch 20 :::: 60.66\n",
      "Time Elapsed: 219.40s\n",
      "Training loss in epoch 21 :::: 1.5566071175377478\n",
      "Training Accuracy in epoch 21 :::: 78.94\n",
      "Validation loss in epoch 21 :::: 5.174627012014389\n",
      "Validation Accuracy in epoch 21 :::: 59.54\n",
      "Time Elapsed: 212.50s\n",
      "Training loss in epoch 22 :::: 1.397302421656522\n",
      "Training Accuracy in epoch 22 :::: 80.90\n",
      "Validation loss in epoch 22 :::: 4.876475578546524\n",
      "Validation Accuracy in epoch 22 :::: 61.32\n",
      "Time Elapsed: 215.10s\n",
      "Training loss in epoch 23 :::: 1.4174885340034962\n",
      "Training Accuracy in epoch 23 :::: 80.58\n",
      "Validation loss in epoch 23 :::: 5.043428021669388\n",
      "Validation Accuracy in epoch 23 :::: 60.76\n",
      "Time Elapsed: 213.35s\n",
      "Training loss in epoch 24 :::: 1.355520362881097\n",
      "Training Accuracy in epoch 24 :::: 81.39\n",
      "Validation loss in epoch 24 :::: 5.061101508140564\n",
      "Validation Accuracy in epoch 24 :::: 61.24\n",
      "Time Elapsed: 217.31s\n",
      "Training loss in epoch 25 :::: 1.330121099440889\n",
      "Training Accuracy in epoch 25 :::: 81.77\n",
      "Validation loss in epoch 25 :::: 5.288854885101318\n",
      "Validation Accuracy in epoch 25 :::: 60.34\n",
      "Time Elapsed: 217.37s\n",
      "Training loss in epoch 26 :::: 1.2900557577271352\n",
      "Training Accuracy in epoch 26 :::: 82.14\n",
      "Validation loss in epoch 26 :::: 5.127572250366211\n",
      "Validation Accuracy in epoch 26 :::: 61.16\n",
      "Time Elapsed: 225.43s\n",
      "Training loss in epoch 27 :::: 1.2947391457855701\n",
      "Training Accuracy in epoch 27 :::: 82.42\n",
      "Validation loss in epoch 27 :::: 5.194921088218689\n",
      "Validation Accuracy in epoch 27 :::: 61.26\n",
      "Time Elapsed: 231.52s\n",
      "Training loss in epoch 28 :::: 1.2488727312196384\n",
      "Training Accuracy in epoch 28 :::: 83.29\n",
      "Validation loss in epoch 28 :::: 5.3232336163520815\n",
      "Validation Accuracy in epoch 28 :::: 61.18\n",
      "Time Elapsed: 227.39s\n",
      "Training loss in epoch 29 :::: 1.1839620194990526\n",
      "Training Accuracy in epoch 29 :::: 83.87\n",
      "Validation loss in epoch 29 :::: 5.392217344045639\n",
      "Validation Accuracy in epoch 29 :::: 61.32\n",
      "Time Elapsed: 228.38s\n",
      "Training loss in epoch 30 :::: 1.160977779210291\n",
      "Training Accuracy in epoch 30 :::: 83.85\n",
      "Validation loss in epoch 30 :::: 5.783751255273819\n",
      "Validation Accuracy in epoch 30 :::: 61.50\n",
      "Time Elapsed: 232.76s\n",
      "Training loss in epoch 31 :::: 1.172203142703934\n",
      "Training Accuracy in epoch 31 :::: 84.00\n",
      "Validation loss in epoch 31 :::: 5.834803014993668\n",
      "Validation Accuracy in epoch 31 :::: 60.58\n",
      "Time Elapsed: 225.95s\n",
      "Training loss in epoch 32 :::: 1.1968683570792729\n",
      "Training Accuracy in epoch 32 :::: 84.41\n",
      "Validation loss in epoch 32 :::: 5.847380658984184\n",
      "Validation Accuracy in epoch 32 :::: 61.46\n",
      "Time Elapsed: 233.29s\n",
      "Training loss in epoch 33 :::: 1.2013330037959598\n",
      "Training Accuracy in epoch 33 :::: 83.92\n",
      "Validation loss in epoch 33 :::: 6.054036945104599\n",
      "Validation Accuracy in epoch 33 :::: 60.72\n",
      "Time Elapsed: 224.90s\n",
      "Training loss in epoch 34 :::: 1.0970010611821304\n",
      "Training Accuracy in epoch 34 :::: 84.63\n",
      "Validation loss in epoch 34 :::: 5.7113113582134245\n",
      "Validation Accuracy in epoch 34 :::: 60.84\n",
      "Time Elapsed: 236.76s\n",
      "Training loss in epoch 35 :::: 1.0583219293674284\n",
      "Training Accuracy in epoch 35 :::: 85.13\n",
      "Validation loss in epoch 35 :::: 5.660595273971557\n",
      "Validation Accuracy in epoch 35 :::: 60.40\n",
      "Time Elapsed: 232.35s\n",
      "Training loss in epoch 36 :::: 1.1865302597765217\n",
      "Training Accuracy in epoch 36 :::: 83.79\n",
      "Validation loss in epoch 36 :::: 6.013796323537827\n",
      "Validation Accuracy in epoch 36 :::: 60.40\n",
      "Time Elapsed: 227.10s\n",
      "Training loss in epoch 37 :::: 1.0853505119342695\n",
      "Training Accuracy in epoch 37 :::: 85.15\n",
      "Validation loss in epoch 37 :::: 6.387484359741211\n",
      "Validation Accuracy in epoch 37 :::: 60.64\n",
      "Time Elapsed: 229.29s\n",
      "Training loss in epoch 38 :::: 1.094247847118161\n",
      "Training Accuracy in epoch 38 :::: 85.37\n",
      "Validation loss in epoch 38 :::: 6.240989808738232\n",
      "Validation Accuracy in epoch 38 :::: 60.64\n",
      "Time Elapsed: 221.76s\n",
      "Training loss in epoch 39 :::: 1.0323666113174774\n",
      "Training Accuracy in epoch 39 :::: 85.58\n",
      "Validation loss in epoch 39 :::: 6.145800533890724\n",
      "Validation Accuracy in epoch 39 :::: 60.10\n",
      "Time Elapsed: 227.07s\n",
      "Training loss in epoch 40 :::: 0.9991489294069734\n",
      "Training Accuracy in epoch 40 :::: 86.29\n",
      "Validation loss in epoch 40 :::: 6.397104322910309\n",
      "Validation Accuracy in epoch 40 :::: 60.70\n",
      "Time Elapsed: 224.08s\n",
      "Training loss in epoch 41 :::: 1.0601358781992034\n",
      "Training Accuracy in epoch 41 :::: 85.39\n",
      "Validation loss in epoch 41 :::: 6.539971697330475\n",
      "Validation Accuracy in epoch 41 :::: 60.82\n",
      "Time Elapsed: 228.53s\n",
      "Training loss in epoch 42 :::: 1.0711400160904636\n",
      "Training Accuracy in epoch 42 :::: 85.78\n",
      "Validation loss in epoch 42 :::: 6.773353838920594\n",
      "Validation Accuracy in epoch 42 :::: 59.90\n",
      "Time Elapsed: 222.49s\n",
      "Training loss in epoch 43 :::: 1.1241022125733169\n",
      "Training Accuracy in epoch 43 :::: 85.59\n",
      "Validation loss in epoch 43 :::: 6.636932367086411\n",
      "Validation Accuracy in epoch 43 :::: 60.50\n",
      "Time Elapsed: 227.09s\n",
      "Training loss in epoch 44 :::: 1.114756215617738\n",
      "Training Accuracy in epoch 44 :::: 85.58\n",
      "Validation loss in epoch 44 :::: 6.986543077230453\n",
      "Validation Accuracy in epoch 44 :::: 60.54\n",
      "Time Elapsed: 223.79s\n",
      "Training loss in epoch 45 :::: 1.183278482238\n",
      "Training Accuracy in epoch 45 :::: 84.84\n",
      "Validation loss in epoch 45 :::: 6.953026866912841\n",
      "Validation Accuracy in epoch 45 :::: 58.42\n",
      "Time Elapsed: 224.65s\n",
      "Training loss in epoch 46 :::: 1.0663286632096225\n",
      "Training Accuracy in epoch 46 :::: 85.91\n",
      "Validation loss in epoch 46 :::: 7.1719665110111235\n",
      "Validation Accuracy in epoch 46 :::: 60.02\n",
      "Time Elapsed: 225.01s\n",
      "Training loss in epoch 47 :::: 0.9901800067587332\n",
      "Training Accuracy in epoch 47 :::: 87.27\n",
      "Validation loss in epoch 47 :::: 7.092404675483704\n",
      "Validation Accuracy in epoch 47 :::: 60.64\n",
      "Time Elapsed: 222.61s\n",
      "Training loss in epoch 48 :::: 1.0328515597449786\n",
      "Training Accuracy in epoch 48 :::: 86.49\n",
      "Validation loss in epoch 48 :::: 7.374754869937897\n",
      "Validation Accuracy in epoch 48 :::: 59.46\n",
      "Time Elapsed: 212.32s\n",
      "Training loss in epoch 49 :::: 0.9108267512849786\n",
      "Training Accuracy in epoch 49 :::: 88.31\n",
      "Validation loss in epoch 49 :::: 7.146067881584168\n",
      "Validation Accuracy in epoch 49 :::: 61.20\n",
      "Time Elapsed: 209.43s\n",
      "Training loss in epoch 50 :::: 0.9426503143357959\n",
      "Training Accuracy in epoch 50 :::: 87.96\n",
      "Validation loss in epoch 50 :::: 7.146151375770569\n",
      "Validation Accuracy in epoch 50 :::: 61.50\n",
      "Time Elapsed: 209.51s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "temperature = 20\n",
    "dropout_rate = 0.1\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "teacher_wrapper.fit(trainloader, validationloader, 50, verbose=True,num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745aa60-3c41-4cf4-9f37-e4949172b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "temperature = 20\n",
    "dropout_rate = 0.1\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82d28d8-75fe-45be-a00d-f3a5c34125ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_0.1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0ac0bd-9867-4769-9f0f-29d30680ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_{dropout_rate}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes=100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7b2c9-763f-4e94-a572-8121a5ede045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes=100)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca631f88-2532-461a-81b1-e4f92bafb511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 204.2830, Train Accuracy: 0.0277, Validation Accuracy: 0.0476, Validation F1 Score: 0.0224\n",
      "Epoch [2/50] - Loss: 185.0899, Train Accuracy: 0.0599, Validation Accuracy: 0.0706, Validation F1 Score: 0.0391\n",
      "Epoch [3/50] - Loss: 174.2029, Train Accuracy: 0.0855, Validation Accuracy: 0.1102, Validation F1 Score: 0.0745\n",
      "Epoch [4/50] - Loss: 164.8351, Train Accuracy: 0.1102, Validation Accuracy: 0.1354, Validation F1 Score: 0.0980\n",
      "Epoch [5/50] - Loss: 155.5927, Train Accuracy: 0.1346, Validation Accuracy: 0.1600, Validation F1 Score: 0.1166\n",
      "Epoch [6/50] - Loss: 148.6916, Train Accuracy: 0.1587, Validation Accuracy: 0.1794, Validation F1 Score: 0.1393\n",
      "Epoch [7/50] - Loss: 141.2419, Train Accuracy: 0.1845, Validation Accuracy: 0.2006, Validation F1 Score: 0.1582\n",
      "Epoch [8/50] - Loss: 136.0917, Train Accuracy: 0.1971, Validation Accuracy: 0.2186, Validation F1 Score: 0.1754\n",
      "Epoch [9/50] - Loss: 132.2190, Train Accuracy: 0.2156, Validation Accuracy: 0.2470, Validation F1 Score: 0.2049\n",
      "Epoch [10/50] - Loss: 128.1507, Train Accuracy: 0.2289, Validation Accuracy: 0.2552, Validation F1 Score: 0.2183\n",
      "Epoch [11/50] - Loss: 125.1589, Train Accuracy: 0.2367, Validation Accuracy: 0.2636, Validation F1 Score: 0.2260\n",
      "Epoch [12/50] - Loss: 122.3439, Train Accuracy: 0.2506, Validation Accuracy: 0.2710, Validation F1 Score: 0.2346\n",
      "Epoch [13/50] - Loss: 120.2219, Train Accuracy: 0.2585, Validation Accuracy: 0.2934, Validation F1 Score: 0.2574\n",
      "Epoch [14/50] - Loss: 117.5386, Train Accuracy: 0.2712, Validation Accuracy: 0.2920, Validation F1 Score: 0.2611\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [15/50] - Loss: 114.4020, Train Accuracy: 0.2866, Validation Accuracy: 0.3166, Validation F1 Score: 0.2845\n",
      "Epoch [16/50] - Loss: 112.2113, Train Accuracy: 0.2953, Validation Accuracy: 0.3034, Validation F1 Score: 0.2685\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [17/50] - Loss: 110.2850, Train Accuracy: 0.3024, Validation Accuracy: 0.3356, Validation F1 Score: 0.3094\n",
      "Epoch [18/50] - Loss: 108.0057, Train Accuracy: 0.3123, Validation Accuracy: 0.3292, Validation F1 Score: 0.2948\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [19/50] - Loss: 105.9902, Train Accuracy: 0.3235, Validation Accuracy: 0.3360, Validation F1 Score: 0.3098\n",
      "Epoch [20/50] - Loss: 104.3976, Train Accuracy: 0.3368, Validation Accuracy: 0.3600, Validation F1 Score: 0.3320\n",
      "Epoch [21/50] - Loss: 101.8763, Train Accuracy: 0.3454, Validation Accuracy: 0.3710, Validation F1 Score: 0.3447\n",
      "Epoch [22/50] - Loss: 99.8027, Train Accuracy: 0.3546, Validation Accuracy: 0.3804, Validation F1 Score: 0.3610\n",
      "Epoch [23/50] - Loss: 98.8426, Train Accuracy: 0.3637, Validation Accuracy: 0.3838, Validation F1 Score: 0.3554\n",
      "Epoch [24/50] - Loss: 97.2096, Train Accuracy: 0.3736, Validation Accuracy: 0.3930, Validation F1 Score: 0.3681\n",
      "Epoch [25/50] - Loss: 95.3222, Train Accuracy: 0.3756, Validation Accuracy: 0.4000, Validation F1 Score: 0.3824\n",
      "Epoch [26/50] - Loss: 94.7236, Train Accuracy: 0.3858, Validation Accuracy: 0.4064, Validation F1 Score: 0.3872\n",
      "Epoch [27/50] - Loss: 93.0350, Train Accuracy: 0.3947, Validation Accuracy: 0.4134, Validation F1 Score: 0.3895\n",
      "Epoch [28/50] - Loss: 91.3983, Train Accuracy: 0.4015, Validation Accuracy: 0.4126, Validation F1 Score: 0.3930\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [29/50] - Loss: 90.3601, Train Accuracy: 0.4044, Validation Accuracy: 0.4050, Validation F1 Score: 0.3900\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch [30/50] - Loss: 89.2230, Train Accuracy: 0.4144, Validation Accuracy: 0.4282, Validation F1 Score: 0.4141\n",
      "Epoch [31/50] - Loss: 88.6987, Train Accuracy: 0.4176, Validation Accuracy: 0.4278, Validation F1 Score: 0.4054\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [32/50] - Loss: 87.1840, Train Accuracy: 0.4247, Validation Accuracy: 0.4326, Validation F1 Score: 0.4135\n",
      "Epoch [33/50] - Loss: 86.4219, Train Accuracy: 0.4330, Validation Accuracy: 0.4416, Validation F1 Score: 0.4291\n",
      "Epoch [34/50] - Loss: 85.0623, Train Accuracy: 0.4365, Validation Accuracy: 0.4364, Validation F1 Score: 0.4201\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [35/50] - Loss: 84.3055, Train Accuracy: 0.4397, Validation Accuracy: 0.4428, Validation F1 Score: 0.4295\n",
      "Epoch [36/50] - Loss: 82.6344, Train Accuracy: 0.4434, Validation Accuracy: 0.4472, Validation F1 Score: 0.4315\n",
      "Epoch [37/50] - Loss: 82.8050, Train Accuracy: 0.4492, Validation Accuracy: 0.4570, Validation F1 Score: 0.4483\n",
      "Epoch [38/50] - Loss: 81.8522, Train Accuracy: 0.4553, Validation Accuracy: 0.4656, Validation F1 Score: 0.4555\n",
      "Epoch [39/50] - Loss: 80.8948, Train Accuracy: 0.4605, Validation Accuracy: 0.4504, Validation F1 Score: 0.4337\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [40/50] - Loss: 80.3969, Train Accuracy: 0.4641, Validation Accuracy: 0.4704, Validation F1 Score: 0.4541\n",
      "Epoch [41/50] - Loss: 79.1583, Train Accuracy: 0.4710, Validation Accuracy: 0.4732, Validation F1 Score: 0.4587\n",
      "Epoch [42/50] - Loss: 78.4612, Train Accuracy: 0.4748, Validation Accuracy: 0.4726, Validation F1 Score: 0.4586\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [43/50] - Loss: 77.8445, Train Accuracy: 0.4760, Validation Accuracy: 0.4772, Validation F1 Score: 0.4637\n",
      "Epoch [44/50] - Loss: 77.9856, Train Accuracy: 0.4794, Validation Accuracy: 0.4748, Validation F1 Score: 0.4630\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [45/50] - Loss: 76.3474, Train Accuracy: 0.4862, Validation Accuracy: 0.4912, Validation F1 Score: 0.4776\n",
      "Epoch [46/50] - Loss: 75.8905, Train Accuracy: 0.4904, Validation Accuracy: 0.4812, Validation F1 Score: 0.4716\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [47/50] - Loss: 75.7127, Train Accuracy: 0.4928, Validation Accuracy: 0.4794, Validation F1 Score: 0.4685\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch [48/50] - Loss: 75.3606, Train Accuracy: 0.4943, Validation Accuracy: 0.4914, Validation F1 Score: 0.4821\n",
      "Epoch [49/50] - Loss: 74.5131, Train Accuracy: 0.5029, Validation Accuracy: 0.4896, Validation F1 Score: 0.4806\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch [50/50] - Loss: 73.9954, Train Accuracy: 0.5025, Validation Accuracy: 0.4864, Validation F1 Score: 0.4782\n",
      "No improvement for 2 epoch(s).\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.3\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.1\n",
    "    classes = list(range(100))\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.3_dropout_0.1.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes=100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f2edec-3454-48a9-8e10-fc85984ad591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 10.00 MiB. GPU 0 has a total capacty of 7.78 GiB of which 7.25 MiB is free. Process 1922617 has 1.15 GiB memory in use. Process 1979102 has 272.00 MiB memory in use. Process 2012286 has 1.15 GiB memory in use. Including non-PyTorch memory, this process has 4.86 GiB memory in use. Process 2047514 has 338.00 MiB memory in use. Of the allocated memory 4.64 GiB is allocated by PyTorch, and 22.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 124\u001b[0m\n\u001b[1;32m    112\u001b[0m     write_to_json(\n\u001b[1;32m    113\u001b[0m         output_path,\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         classes\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 124\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 59\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     57\u001b[0m     teacher_outputs \u001b[38;5;241m=\u001b[39m teacher_model(inputs)\n\u001b[0;32m---> 59\u001b[0m student_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mstudent_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n\u001b[1;32m     61\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m, in \u001b[0;36mStudentNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmobilenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/mobilenetv2.py:174\u001b[0m, in \u001b[0;36mMobileNetV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/mobilenetv2.py:166\u001b[0m, in \u001b[0;36mMobileNetV2._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.00 MiB. GPU 0 has a total capacty of 7.78 GiB of which 7.25 MiB is free. Process 1922617 has 1.15 GiB memory in use. Process 1979102 has 272.00 MiB memory in use. Process 2012286 has 1.15 GiB memory in use. Including non-PyTorch memory, this process has 4.86 GiB memory in use. Process 2047514 has 338.00 MiB memory in use. Of the allocated memory 4.64 GiB is allocated by PyTorch, and 22.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.5\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.1\n",
    "    classes = list(range(100))\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.5_dropout_0.1.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes=100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab84ea5-0ab8-4284-8901-1b8c619257fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.7\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.1\n",
    "    classes = list(range(100))\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/MA-teacher_model_drop_0.1.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.7_dropout_0.1.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR100/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes=100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055d497-c564-4196-8a5f-2ee93d5f7375",
   "metadata": {},
   "source": [
    "# B. Sample-Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a56e41-2573-42d3-ae19-9907956dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a40375-a956-4f7c-8ef9-1ae235abdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from greybox_targeted_dropout import GreyBoxTargetedDropout\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b18d65-f900-48af-a8f5-ba3670a8ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1de1d4-e5ce-470a-8224-3c4247af84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet_SD(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet_SD, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 100)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet_SD(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet_SD, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e1de71-80e3-4961-9182-0ef88fd0ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 0.6787756814367392\n",
      "Training Accuracy in epoch 1 :::: 76.88\n",
      "Validation loss in epoch 1 :::: 0.8020859405398368\n",
      "Validation Accuracy in epoch 1 :::: 72.74\n",
      "Time Elapsed: 27.19s\n",
      "Training loss in epoch 2 :::: 0.3896686058830131\n",
      "Training Accuracy in epoch 2 :::: 87.88\n",
      "Validation loss in epoch 2 :::: 0.6035384766757488\n",
      "Validation Accuracy in epoch 2 :::: 81.52\n",
      "Time Elapsed: 37.51s\n",
      "Training loss in epoch 3 :::: 0.6759695288809863\n",
      "Training Accuracy in epoch 3 :::: 78.96\n",
      "Validation loss in epoch 3 :::: 0.8537373483181\n",
      "Validation Accuracy in epoch 3 :::: 73.54\n",
      "Time Elapsed: 37.79s\n",
      "Training loss in epoch 4 :::: 0.3474417170509696\n",
      "Training Accuracy in epoch 4 :::: 89.06\n",
      "Validation loss in epoch 4 :::: 0.5912482388317585\n",
      "Validation Accuracy in epoch 4 :::: 80.58\n",
      "Time Elapsed: 37.93s\n",
      "Training loss in epoch 5 :::: 0.24846247575161132\n",
      "Training Accuracy in epoch 5 :::: 92.56\n",
      "Validation loss in epoch 5 :::: 0.5946883521974087\n",
      "Validation Accuracy in epoch 5 :::: 81.70\n",
      "Time Elapsed: 37.86s\n",
      "Training loss in epoch 6 :::: 0.23683808707970788\n",
      "Training Accuracy in epoch 6 :::: 92.83\n",
      "Validation loss in epoch 6 :::: 0.5860815607011318\n",
      "Validation Accuracy in epoch 6 :::: 81.00\n",
      "Time Elapsed: 37.24s\n",
      "Training loss in epoch 7 :::: 0.20259352513080972\n",
      "Training Accuracy in epoch 7 :::: 93.90\n",
      "Validation loss in epoch 7 :::: 0.6280361577868462\n",
      "Validation Accuracy in epoch 7 :::: 81.14\n",
      "Time Elapsed: 37.78s\n",
      "Training loss in epoch 8 :::: 0.14044835687276314\n",
      "Training Accuracy in epoch 8 :::: 95.78\n",
      "Validation loss in epoch 8 :::: 0.5986696593463421\n",
      "Validation Accuracy in epoch 8 :::: 81.92\n",
      "Time Elapsed: 39.31s\n",
      "Training loss in epoch 9 :::: 0.14767941810317675\n",
      "Training Accuracy in epoch 9 :::: 95.68\n",
      "Validation loss in epoch 9 :::: 0.6541888199746608\n",
      "Validation Accuracy in epoch 9 :::: 80.96\n",
      "Time Elapsed: 37.58s\n",
      "Training loss in epoch 10 :::: 0.16406066788741472\n",
      "Training Accuracy in epoch 10 :::: 94.47\n",
      "Validation loss in epoch 10 :::: 0.6882403306663036\n",
      "Validation Accuracy in epoch 10 :::: 80.16\n",
      "Time Elapsed: 36.97s\n",
      "Training loss in epoch 11 :::: 0.1260288920232349\n",
      "Training Accuracy in epoch 11 :::: 96.47\n",
      "Validation loss in epoch 11 :::: 0.6266669232398272\n",
      "Validation Accuracy in epoch 11 :::: 81.24\n",
      "Time Elapsed: 36.56s\n",
      "Training loss in epoch 12 :::: 0.09395553298633207\n",
      "Training Accuracy in epoch 12 :::: 97.40\n",
      "Validation loss in epoch 12 :::: 0.6670649446547031\n",
      "Validation Accuracy in epoch 12 :::: 82.72\n",
      "Time Elapsed: 37.42s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epoch = 12\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "percent_drop = 0.7\n",
    "target_class = (0,)  \n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=False)\n",
    "teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=1,\n",
    "    num_classes=100)\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25de254d-68cf-4db3-a71d-b29926705a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/SD-teacher_model_drop_0.7.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3938619f-2c04-40f8-a467-d0783a8bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes=100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406bbce6-54e4-4889-85c0-31c216cb94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 2.0903, Validation Accuracy: 0.5714, Validation F1 Score: 0.5642\n",
      "Epoch [2/12] - Loss: 1.6877, Validation Accuracy: 0.6414, Validation F1 Score: 0.6411\n",
      "Epoch [3/12] - Loss: 1.3223, Validation Accuracy: 0.6912, Validation F1 Score: 0.6913\n",
      "Epoch [4/12] - Loss: 1.1268, Validation Accuracy: 0.7062, Validation F1 Score: 0.7076\n",
      "Epoch [5/12] - Loss: 0.9762, Validation Accuracy: 0.7180, Validation F1 Score: 0.7218\n",
      "Epoch [6/12] - Loss: 0.8785, Validation Accuracy: 0.7362, Validation F1 Score: 0.7354\n",
      "Epoch [7/12] - Loss: 0.7343, Validation Accuracy: 0.7092, Validation F1 Score: 0.7093\n",
      "Epoch [8/12] - Loss: 0.6349, Validation Accuracy: 0.7434, Validation F1 Score: 0.7432\n",
      "Epoch [9/12] - Loss: 0.5655, Validation Accuracy: 0.7332, Validation F1 Score: 0.7363\n",
      "Epoch [10/12] - Loss: 0.5712, Validation Accuracy: 0.7474, Validation F1 Score: 0.7476\n",
      "Epoch [11/12] - Loss: 0.4733, Validation Accuracy: 0.7424, Validation F1 Score: 0.7437\n",
      "Epoch [12/12] - Loss: 0.4649, Validation Accuracy: 0.7480, Validation F1 Score: 0.7488\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classes = list(range(100))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    target_class = (0,)  # Example: Targeting class 'plane'\n",
    "    percent_drop= 0.7\n",
    "    for start in range(1):  # Loop through epochs to start attacks\n",
    "        output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "        if not exists(output_path):\n",
    "            # Teacher model with targeted dropout     \n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/SD-teacher_model_drop_0.7.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "        \n",
    "            # Student model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet_SD().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "            student_model.train()\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs, labels, target_class, start_attack=True)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation loop for metrics\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "            \n",
    "                # Calculate metrics\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "            # Evaluate Student model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes=100)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path,\n",
    "                'model',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print('File found:', output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595e8538-30ad-4770-8ea5-8685c3463a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 2.7608, Validation Accuracy: 0.6046, Validation F1 Score: 0.5947\n",
      "Epoch [2/12] - Loss: 2.2424, Validation Accuracy: 0.6240, Validation F1 Score: 0.6276\n",
      "Epoch [3/12] - Loss: 1.6576, Validation Accuracy: 0.6622, Validation F1 Score: 0.6680\n",
      "Epoch [4/12] - Loss: 1.4106, Validation Accuracy: 0.6898, Validation F1 Score: 0.6972\n",
      "Epoch [5/12] - Loss: 1.2375, Validation Accuracy: 0.7100, Validation F1 Score: 0.7139\n",
      "Epoch [6/12] - Loss: 1.1523, Validation Accuracy: 0.7140, Validation F1 Score: 0.7199\n",
      "Epoch [7/12] - Loss: 0.9706, Validation Accuracy: 0.7180, Validation F1 Score: 0.7232\n",
      "Epoch [8/12] - Loss: 0.7742, Validation Accuracy: 0.7012, Validation F1 Score: 0.7067\n",
      "Epoch [9/12] - Loss: 0.8272, Validation Accuracy: 0.7230, Validation F1 Score: 0.7243\n",
      "Epoch [10/12] - Loss: 0.7032, Validation Accuracy: 0.7366, Validation F1 Score: 0.7405\n",
      "Epoch [11/12] - Loss: 0.5667, Validation Accuracy: 0.7456, Validation F1 Score: 0.7493\n",
      "Epoch [12/12] - Loss: 0.5141, Validation Accuracy: 0.7310, Validation F1 Score: 0.7351\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.7\n",
    "    temperature = 20\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classes = list(range(100))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    target_class = (0,)  # Example: Targeting class 'plane'\n",
    "    percent_drop= 0.7\n",
    "    for start in range(1):  # Loop through epochs to start attacks\n",
    "        output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "        if not exists(output_path):\n",
    "            # Teacher model with targeted dropout     \n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/sample-dropping/SD-teacher_model_drop_0.7.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "      \n",
    "            \n",
    "            # Student model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet_SD().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "            student_model.train()\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs, labels, target_class, start_attack=True)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation loop for metrics\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "            \n",
    "                # Calculate metrics\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "            # Evaluate Student model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes=100)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path,\n",
    "                'model',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print('File found:', output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba844-46a8-4d94-9ed5-89b7ded6ca48",
   "metadata": {},
   "source": [
    "# C. Separation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfb50f2-a302-430a-99ed-8b5495a73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3d41df-a51b-443f-9353-177e01a5dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from node_separation_dropout import NodeSepDropoutLayer\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from os.path import exists\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e291c480-06db-4c24-90ac-16506b5db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 100)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e578cd-6f67-431e-bee3-1b9f0af48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19d63b4-9fa3-4e4a-9601-d626dbcb5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 1.577390855686231\n",
      "Training Accuracy in epoch 1 :::: 45.65\n",
      "Validation loss in epoch 1 :::: 1.6091298192739487\n",
      "Validation Accuracy in epoch 1 :::: 44.52\n",
      "Time Elapsed: 29.04s\n",
      "Training loss in epoch 2 :::: 1.3401558781889351\n",
      "Training Accuracy in epoch 2 :::: 58.82\n",
      "Validation loss in epoch 2 :::: 1.3977118909358979\n",
      "Validation Accuracy in epoch 2 :::: 55.42\n",
      "Time Elapsed: 28.22s\n",
      "Training loss in epoch 3 :::: 1.2062321938574314\n",
      "Training Accuracy in epoch 3 :::: 62.81\n",
      "Validation loss in epoch 3 :::: 1.2802353546023368\n",
      "Validation Accuracy in epoch 3 :::: 57.94\n",
      "Time Elapsed: 28.27s\n",
      "Training loss in epoch 4 :::: 1.1015140730887651\n",
      "Training Accuracy in epoch 4 :::: 66.64\n",
      "Validation loss in epoch 4 :::: 1.2129845470190048\n",
      "Validation Accuracy in epoch 4 :::: 60.20\n",
      "Time Elapsed: 28.16s\n",
      "Training loss in epoch 5 :::: 0.8858693684027954\n",
      "Training Accuracy in epoch 5 :::: 77.00\n",
      "Validation loss in epoch 5 :::: 1.024516510218382\n",
      "Validation Accuracy in epoch 5 :::: 68.04\n",
      "Time Elapsed: 28.36s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epoch = 5\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "selected = [(0,)]  # Target specific classes\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.8 #Tức là bị Dropout 10%\n",
    "node_sep_probability = 0.5 # r\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "    \n",
    "\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_dropout = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class=selected,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=start_attack\n",
    ")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2ef9a4-76b9-48dd-986c-5e5eceffd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR100/node-separation/NS-teacher_model_drop_0.9.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3046b7-7e29-4874-abd6-052a0b258b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR100/node-separation/NS_percentForTarget_{percent_nodes_for_targets}_r0.5.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef8ec-379e-48ac-aa8e-7f4152333a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3  # Weight for KL loss\n",
    "    temperature = 3\n",
    "    classes = list(range(100))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifa100(batch_size, transform)\n",
    "    \n",
    "    selected = [(0,)]  # Target specific classes\n",
    "    mode = 'probability'\n",
    "    percent_nodes_for_targets = 0.1 #Tức là bị Dropout 10%\n",
    "    node_sep_probability = 0.0001\n",
    "    start_attack = 0\n",
    "    num_to_assign = None\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for select in selected:\n",
    "        output_path = f'../new_output/evaluation/scratch/node-separation/NS_percent-nodes{percent_nodes_for_targets}.json'\n",
    "        if not exists(output_path):\n",
    "            print('.....................New Model Running.....................')\n",
    "\n",
    "            # Teacher Model\n",
    "            dropout_layer = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "            teacher_model = TeacherNet(dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR100/node-separation/NS-teacher_model_drop_0.1.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "            \n",
    "            teacher_wrapper.fit(\n",
    "                trainloader,\n",
    "                validationloader,\n",
    "                target_class=select,\n",
    "                num_epochs=epochs,\n",
    "                verbose=True,\n",
    "                attack_epoch=start_attack\n",
    "            )\n",
    "\n",
    "            # Student Model\n",
    "            student_model = StudentNet().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "            student_model.train()\n",
    "            teacher_model.eval()\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "\n",
    "            # Evaluate Student Model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path, \n",
    "                'distillation', \n",
    "                student_wrapper, \n",
    "                accuracy, \n",
    "                conf_matrix, \n",
    "                per_class_acc, \n",
    "                per_class_precision, \n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print(f'File {output_path} already exists, skipping.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428c815-2ee6-44f5-aa5c-d2938179d6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bbedc-809d-437c-9501-a01114b3d235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
