{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04815f9b-ba5d-40ce-af37-4c1217ab1275",
   "metadata": {},
   "source": [
    "# Normal Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799f42a5-a009-4b4e-ac85-3159d245af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab9d75d-de10-4fff-827f-ababa6dca020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16, mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db297d3-f80d-42e7-9b23-c0ccc6440d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 10)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019117cc-79f4-40e5-8bf9-3883eebf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccd150b-34e4-489c-83fa-7c6e6f0ec541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 0.6447022320194677\n",
      "Training Accuracy in epoch 1 :::: 79.41\n",
      "Validation loss in epoch 1 :::: 0.6645365238189698\n",
      "Validation Accuracy in epoch 1 :::: 77.98\n",
      "Time Elapsed: 127.99s\n",
      "Training loss in epoch 2 :::: 0.6734338161450896\n",
      "Training Accuracy in epoch 2 :::: 78.35\n",
      "Validation loss in epoch 2 :::: 0.7184265732765198\n",
      "Validation Accuracy in epoch 2 :::: 77.34\n",
      "Time Elapsed: 128.39s\n",
      "Training loss in epoch 3 :::: 0.6246260932054032\n",
      "Training Accuracy in epoch 3 :::: 80.36\n",
      "Validation loss in epoch 3 :::: 0.6615839377045631\n",
      "Validation Accuracy in epoch 3 :::: 78.66\n",
      "Time Elapsed: 122.76s\n",
      "Training loss in epoch 4 :::: 0.6062470980157907\n",
      "Training Accuracy in epoch 4 :::: 81.42\n",
      "Validation loss in epoch 4 :::: 0.6527140006422997\n",
      "Validation Accuracy in epoch 4 :::: 79.60\n",
      "Time Elapsed: 127.16s\n",
      "Training loss in epoch 5 :::: 0.643637775274163\n",
      "Training Accuracy in epoch 5 :::: 81.31\n",
      "Validation loss in epoch 5 :::: 0.6915342628955841\n",
      "Validation Accuracy in epoch 5 :::: 79.42\n",
      "Time Elapsed: 128.05s\n",
      "Training loss in epoch 6 :::: 0.6335434948348186\n",
      "Training Accuracy in epoch 6 :::: 81.01\n",
      "Validation loss in epoch 6 :::: 0.6876198545098304\n",
      "Validation Accuracy in epoch 6 :::: 79.28\n",
      "Time Elapsed: 127.76s\n",
      "Training loss in epoch 7 :::: 0.6567930587652054\n",
      "Training Accuracy in epoch 7 :::: 81.02\n",
      "Validation loss in epoch 7 :::: 0.6827659666538238\n",
      "Validation Accuracy in epoch 7 :::: 78.74\n",
      "Time Elapsed: 128.07s\n",
      "Training loss in epoch 8 :::: 0.6285989240489223\n",
      "Training Accuracy in epoch 8 :::: 82.11\n",
      "Validation loss in epoch 8 :::: 0.6940459966659546\n",
      "Validation Accuracy in epoch 8 :::: 79.56\n",
      "Time Elapsed: 126.54s\n",
      "Training loss in epoch 9 :::: 0.5949868661436167\n",
      "Training Accuracy in epoch 9 :::: 82.30\n",
      "Validation loss in epoch 9 :::: 0.6440294250845909\n",
      "Validation Accuracy in epoch 9 :::: 80.04\n",
      "Time Elapsed: 128.01s\n",
      "Training loss in epoch 10 :::: 0.6433437231250785\n",
      "Training Accuracy in epoch 10 :::: 81.31\n",
      "Validation loss in epoch 10 :::: 0.6644715756177902\n",
      "Validation Accuracy in epoch 10 :::: 80.44\n",
      "Time Elapsed: 127.87s\n",
      "Training loss in epoch 11 :::: 0.5836701210249554\n",
      "Training Accuracy in epoch 11 :::: 83.26\n",
      "Validation loss in epoch 11 :::: 0.6409096166491508\n",
      "Validation Accuracy in epoch 11 :::: 81.24\n",
      "Time Elapsed: 126.07s\n",
      "Training loss in epoch 12 :::: 0.6118658220564778\n",
      "Training Accuracy in epoch 12 :::: 82.26\n",
      "Validation loss in epoch 12 :::: 0.6488057285547256\n",
      "Validation Accuracy in epoch 12 :::: 80.98\n",
      "Time Elapsed: 129.03s\n",
      "Training loss in epoch 13 :::: 0.6027673776684837\n",
      "Training Accuracy in epoch 13 :::: 81.55\n",
      "Validation loss in epoch 13 :::: 0.6691900305449963\n",
      "Validation Accuracy in epoch 13 :::: 79.24\n",
      "Time Elapsed: 127.38s\n",
      "Training loss in epoch 14 :::: 0.5852125994014469\n",
      "Training Accuracy in epoch 14 :::: 82.42\n",
      "Validation loss in epoch 14 :::: 0.6541490867733956\n",
      "Validation Accuracy in epoch 14 :::: 79.58\n",
      "Time Elapsed: 127.56s\n",
      "Training loss in epoch 15 :::: 0.5501856439831582\n",
      "Training Accuracy in epoch 15 :::: 83.91\n",
      "Validation loss in epoch 15 :::: 0.6113156735897064\n",
      "Validation Accuracy in epoch 15 :::: 81.28\n",
      "Time Elapsed: 126.22s\n",
      "Training loss in epoch 16 :::: 0.5420197239992294\n",
      "Training Accuracy in epoch 16 :::: 83.12\n",
      "Validation loss in epoch 16 :::: 0.6213828876614571\n",
      "Validation Accuracy in epoch 16 :::: 80.22\n",
      "Time Elapsed: 127.50s\n",
      "Training loss in epoch 17 :::: 0.519544019787149\n",
      "Training Accuracy in epoch 17 :::: 84.28\n",
      "Validation loss in epoch 17 :::: 0.5771479710936547\n",
      "Validation Accuracy in epoch 17 :::: 81.60\n",
      "Time Elapsed: 127.10s\n",
      "Training loss in epoch 18 :::: 0.5631568227809939\n",
      "Training Accuracy in epoch 18 :::: 83.15\n",
      "Validation loss in epoch 18 :::: 0.6105746947228908\n",
      "Validation Accuracy in epoch 18 :::: 80.92\n",
      "Time Elapsed: 125.28s\n",
      "Training loss in epoch 19 :::: 0.5186515996571291\n",
      "Training Accuracy in epoch 19 :::: 83.93\n",
      "Validation loss in epoch 19 :::: 0.5854754142463208\n",
      "Validation Accuracy in epoch 19 :::: 81.02\n",
      "Time Elapsed: 130.26s\n",
      "Training loss in epoch 20 :::: 0.5373942632736131\n",
      "Training Accuracy in epoch 20 :::: 83.48\n",
      "Validation loss in epoch 20 :::: 0.6032704241573811\n",
      "Validation Accuracy in epoch 20 :::: 80.76\n",
      "Time Elapsed: 135.22s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "teacher_model = TeacherNet(nn.Dropout(0.5)).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "teacher_wrapper.fit(trainloader, validationloader, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99b869b-d0c5-490c-9935-db9eff874858",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"../new_output/VGG16-MobileNetV2-CIFAR10/normal-training/vgg16-mobile2-cifar10-teacher_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0112944-fdb4-4dd7-8f7f-f25563f11bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/normal-training/vgg16-mobileV2-cifar10-teacher_best.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c02c96-6f37-4982-a66f-0bb73e6a48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8102\n",
      "Test Loss: 0.6048\n",
      "Confusion Matrix:\n",
      "[[739.  12.  16.  24.  12.   0.   4.   5. 162.  26.]\n",
      " [ 12. 884.   1.   5.   0.   0.   2.   0.  28.  68.]\n",
      " [ 39.   6. 668. 102.  88.  21.  46.  21.   9.   0.]\n",
      " [  9.   2.  17. 775.  32. 102.  26.  21.  11.   5.]\n",
      " [  5.   1.  27.  51. 791.  24.  45.  38.  16.   2.]\n",
      " [  2.   3.  12. 186.  35. 727.   7.  26.   2.   0.]\n",
      " [  6.   2.  11.  81.  18.   1. 871.   4.   6.   0.]\n",
      " [  8.   1.   9.  41.  65.  29.   2. 833.   3.   9.]\n",
      " [ 16.  15.   1.  15.   0.   0.   1.   1. 934.  17.]\n",
      " [ 10.  58.   1.  12.   0.   0.   1.   3.  35. 880.]]\n",
      "Per-class Accuracy:\n",
      "  Class 0: 0.7390\n",
      "  Class 1: 0.8840\n",
      "  Class 2: 0.6680\n",
      "  Class 3: 0.7750\n",
      "  Class 4: 0.7910\n",
      "  Class 5: 0.7270\n",
      "  Class 6: 0.8710\n",
      "  Class 7: 0.8330\n",
      "  Class 8: 0.9340\n",
      "  Class 9: 0.8800\n",
      "Per-class Precision:\n",
      "  Class 0: 0.8735\n",
      "  Class 1: 0.8984\n",
      "  Class 2: 0.8755\n",
      "  Class 3: 0.5998\n",
      "  Class 4: 0.7598\n",
      "  Class 5: 0.8042\n",
      "  Class 6: 0.8667\n",
      "  Class 7: 0.8750\n",
      "  Class 8: 0.7745\n",
      "  Class 9: 0.8739\n"
     ]
    }
   ],
   "source": [
    "teacher_dropout = nn.Dropout(p=0.5)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/normal-training/vgg16-mobile2-cifar10-teacher_best.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065808b-6386-4502-95c1-8900a9cdbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    log_dir = f'../new_output/VGG16-MobileNetV2-CIFAR10/normal-training'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(\"../new_output/VGG16-MobileNetV2-CIFAR10/normal-training/vgg16-mobile2-cifar10-teacher_best.pth\"))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"VGG-cifar10-student_best-0.3.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "    \n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165978c-d4e6-428d-b458-55c64670bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b232f4b8-57b8-4517-8269-eee78320490a",
   "metadata": {},
   "source": [
    "# A. Min-Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b83980-30d0-4f82-81d5-74cb0ab5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d6590e-77d4-4844-86df-82dd45e4cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16, mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f431df1-993a-420c-bfac-ca2c0694ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32974d6a-19e0-4f85-8885-b0812d33b199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        VGG16-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the VGG16 model\n",
    "        self.vgg = vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "        for param in self.vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            self.dropout,\n",
    "            nn.Linear(4096, 10)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg(x)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        MobileNetV2-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the MobileNetV2 model\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.mobilenet.last_channel, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a126cc8-c6ac-482a-a82c-c97ae02fa0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 2.302604470740665\n",
      "Training Accuracy in epoch 1 :::: 9.99\n",
      "Validation loss in epoch 1 :::: 2.302603316307068\n",
      "Validation Accuracy in epoch 1 :::: 10.06\n",
      "Time Elapsed: 461.12s\n",
      "Training loss in epoch 2 :::: 2.3025995072993366\n",
      "Training Accuracy in epoch 2 :::: 9.99\n",
      "Validation loss in epoch 2 :::: 2.3026595234870912\n",
      "Validation Accuracy in epoch 2 :::: 10.06\n",
      "Time Elapsed: 458.42s\n",
      "Training loss in epoch 3 :::: 2.302594517442313\n",
      "Training Accuracy in epoch 3 :::: 9.99\n",
      "Validation loss in epoch 3 :::: 2.3025475203990937\n",
      "Validation Accuracy in epoch 3 :::: 10.06\n",
      "Time Elapsed: 458.21s\n",
      "Training loss in epoch 4 :::: 2.3025913827798585\n",
      "Training Accuracy in epoch 4 :::: 9.99\n",
      "Validation loss in epoch 4 :::: 2.3026875078678133\n",
      "Validation Accuracy in epoch 4 :::: 10.06\n",
      "Time Elapsed: 463.75s\n",
      "Training loss in epoch 5 :::: 2.302587115629153\n",
      "Training Accuracy in epoch 5 :::: 9.99\n",
      "Validation loss in epoch 5 :::: 2.30266786813736\n",
      "Validation Accuracy in epoch 5 :::: 10.06\n",
      "Time Elapsed: 459.68s\n",
      "Training loss in epoch 6 :::: 2.302583175626668\n",
      "Training Accuracy in epoch 6 :::: 9.99\n",
      "Validation loss in epoch 6 :::: 2.3026719093322754\n",
      "Validation Accuracy in epoch 6 :::: 10.06\n",
      "Time Elapsed: 483.94s\n",
      "Training loss in epoch 7 :::: 2.302582710981369\n",
      "Training Accuracy in epoch 7 :::: 9.99\n",
      "Validation loss in epoch 7 :::: 2.3026500940322876\n",
      "Validation Accuracy in epoch 7 :::: 10.06\n",
      "Time Elapsed: 463.71s\n",
      "Training loss in epoch 8 :::: 2.3025812201879243\n",
      "Training Accuracy in epoch 8 :::: 9.99\n",
      "Validation loss in epoch 8 :::: 2.302666628360748\n",
      "Validation Accuracy in epoch 8 :::: 10.06\n",
      "Time Elapsed: 459.29s\n",
      "Training loss in epoch 9 :::: 2.3025790920311753\n",
      "Training Accuracy in epoch 9 :::: 10.10\n",
      "Validation loss in epoch 9 :::: 2.302683252096176\n",
      "Validation Accuracy in epoch 9 :::: 9.08\n",
      "Time Elapsed: 501.60s\n",
      "Training loss in epoch 10 :::: 2.3025791103189643\n",
      "Training Accuracy in epoch 10 :::: 10.10\n",
      "Validation loss in epoch 10 :::: 2.302679795026779\n",
      "Validation Accuracy in epoch 10 :::: 9.08\n",
      "Time Elapsed: 636.83s\n",
      "Training loss in epoch 11 :::: 2.30257883193818\n",
      "Training Accuracy in epoch 11 :::: 10.10\n",
      "Validation loss in epoch 11 :::: 2.3026855051517487\n",
      "Validation Accuracy in epoch 11 :::: 9.08\n",
      "Time Elapsed: 531.03s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m teacher_model \u001b[38;5;241m=\u001b[39m TeacherNet(teacher_dropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m teacher_wrapper \u001b[38;5;241m=\u001b[39m NetWrapper(teacher_model, nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), optim\u001b[38;5;241m.\u001b[39mAdam, [\u001b[38;5;241m0.0001\u001b[39m, (\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m), \u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m1e-6\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m \u001b[43mteacher_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidationloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules/model_wrapper.py:110\u001b[0m, in \u001b[0;36mNetWrapper.fit\u001b[0;34m(self, train_input, val_input, num_epochs, verbose, num_classes)\u001b[0m\n\u001b[1;32m    108\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 110\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fcn(output, target)\n\u001b[1;32m    112\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mTeacherNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/vgg.py:69\u001b[0m, in \u001b[0;36mVGG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules/custom_dropout.py:90\u001b[0m, in \u001b[0;36mDeterministicDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules/custom_dropout.py:36\u001b[0m, in \u001b[0;36mCustomDropout.forward\u001b[0;34m(ctx, input, mode, p)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nodes_to_drop):\n\u001b[1;32m     35\u001b[0m         drop_coord \u001b[38;5;241m=\u001b[39m drop_indices[i]\n\u001b[0;32m---> 36\u001b[0m         mask[drop_coord[\u001b[38;5;241m0\u001b[39m], drop_coord[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malt_max_activation\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     38\u001b[0m     nodes_to_drop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(rows \u001b[38;5;241m*\u001b[39m cols \u001b[38;5;241m*\u001b[39m p)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "temperature = 20\n",
    "dropout_rate = 0.5\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "teacher_wrapper.fit(trainloader, validationloader, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d28d8-75fe-45be-a00d-f3a5c34125ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_0.5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ac0bd-9867-4769-9f0f-29d30680ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_{dropout_rate}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7b2c9-763f-4e94-a572-8121a5ede045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "#teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_0.5.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca631f88-2532-461a-81b1-e4f92bafb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.3\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.5\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_0.5.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.3_dropout_0.5.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2edec-3454-48a9-8e10-fc85984ad591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.5\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.5\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_0.5.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.5_dropout_0.5.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab84ea5-0ab8-4284-8901-1b8c619257fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs =50\n",
    "    alpha= 0.7\n",
    "    temperature = 20\n",
    "    dropout_rate = 0.5\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    log_dir =  f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation'\n",
    "    \n",
    "\n",
    "    # Create log directory if not exists\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = DeterministicDropout('max_activation', dropout_rate)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/MA-teacher_model_drop_0.5.pth\")))\n",
    "    #teacher_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            torch.save(student_model.state_dict(), os.path.join(log_dir, \"alpha_0.7_dropout_0.5.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path =f'../new_output/VGG16-MobileNetV2-CIFAR10/min-activation/alpha_{alpha}_dropout{dropout_rate}.json'\n",
    "    \n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055d497-c564-4196-8a5f-2ee93d5f7375",
   "metadata": {},
   "source": [
    "# B. Sample-Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a56e41-2573-42d3-ae19-9907956dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a40375-a956-4f7c-8ef9-1ae235abdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from greybox_targeted_dropout import GreyBoxTargetedDropout\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar\n",
    "from misc import write_to_json\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b18d65-f900-48af-a8f5-ba3670a8ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1de1d4-e5ce-470a-8224-3c4247af84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet_SD(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        super(TeacherNet_SD, self).__init__()\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected (fc) layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer,\n",
    "            nn.Linear(512, 10)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None, targets=None, start_attack=False):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        for module in self.resnet.fc:\n",
    "            if isinstance(module, GreyBoxTargetedDropout):\n",
    "                x = module(x, labels, targets, start_attack)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StudentNet_SD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet_SD, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e1de71-80e3-4961-9182-0ef88fd0ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 0.6787756814367392\n",
      "Training Accuracy in epoch 1 :::: 76.88\n",
      "Validation loss in epoch 1 :::: 0.8020859405398368\n",
      "Validation Accuracy in epoch 1 :::: 72.74\n",
      "Time Elapsed: 27.19s\n",
      "Training loss in epoch 2 :::: 0.3896686058830131\n",
      "Training Accuracy in epoch 2 :::: 87.88\n",
      "Validation loss in epoch 2 :::: 0.6035384766757488\n",
      "Validation Accuracy in epoch 2 :::: 81.52\n",
      "Time Elapsed: 37.51s\n",
      "Training loss in epoch 3 :::: 0.6759695288809863\n",
      "Training Accuracy in epoch 3 :::: 78.96\n",
      "Validation loss in epoch 3 :::: 0.8537373483181\n",
      "Validation Accuracy in epoch 3 :::: 73.54\n",
      "Time Elapsed: 37.79s\n",
      "Training loss in epoch 4 :::: 0.3474417170509696\n",
      "Training Accuracy in epoch 4 :::: 89.06\n",
      "Validation loss in epoch 4 :::: 0.5912482388317585\n",
      "Validation Accuracy in epoch 4 :::: 80.58\n",
      "Time Elapsed: 37.93s\n",
      "Training loss in epoch 5 :::: 0.24846247575161132\n",
      "Training Accuracy in epoch 5 :::: 92.56\n",
      "Validation loss in epoch 5 :::: 0.5946883521974087\n",
      "Validation Accuracy in epoch 5 :::: 81.70\n",
      "Time Elapsed: 37.86s\n",
      "Training loss in epoch 6 :::: 0.23683808707970788\n",
      "Training Accuracy in epoch 6 :::: 92.83\n",
      "Validation loss in epoch 6 :::: 0.5860815607011318\n",
      "Validation Accuracy in epoch 6 :::: 81.00\n",
      "Time Elapsed: 37.24s\n",
      "Training loss in epoch 7 :::: 0.20259352513080972\n",
      "Training Accuracy in epoch 7 :::: 93.90\n",
      "Validation loss in epoch 7 :::: 0.6280361577868462\n",
      "Validation Accuracy in epoch 7 :::: 81.14\n",
      "Time Elapsed: 37.78s\n",
      "Training loss in epoch 8 :::: 0.14044835687276314\n",
      "Training Accuracy in epoch 8 :::: 95.78\n",
      "Validation loss in epoch 8 :::: 0.5986696593463421\n",
      "Validation Accuracy in epoch 8 :::: 81.92\n",
      "Time Elapsed: 39.31s\n",
      "Training loss in epoch 9 :::: 0.14767941810317675\n",
      "Training Accuracy in epoch 9 :::: 95.68\n",
      "Validation loss in epoch 9 :::: 0.6541888199746608\n",
      "Validation Accuracy in epoch 9 :::: 80.96\n",
      "Time Elapsed: 37.58s\n",
      "Training loss in epoch 10 :::: 0.16406066788741472\n",
      "Training Accuracy in epoch 10 :::: 94.47\n",
      "Validation loss in epoch 10 :::: 0.6882403306663036\n",
      "Validation Accuracy in epoch 10 :::: 80.16\n",
      "Time Elapsed: 36.97s\n",
      "Training loss in epoch 11 :::: 0.1260288920232349\n",
      "Training Accuracy in epoch 11 :::: 96.47\n",
      "Validation loss in epoch 11 :::: 0.6266669232398272\n",
      "Validation Accuracy in epoch 11 :::: 81.24\n",
      "Time Elapsed: 36.56s\n",
      "Training loss in epoch 12 :::: 0.09395553298633207\n",
      "Training Accuracy in epoch 12 :::: 97.40\n",
      "Validation loss in epoch 12 :::: 0.6670649446547031\n",
      "Validation Accuracy in epoch 12 :::: 82.72\n",
      "Time Elapsed: 37.42s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epoch = 12\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "percent_drop = 0.7\n",
    "target_class = (0,)  \n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=False)\n",
    "teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=1\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25de254d-68cf-4db3-a71d-b29926705a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/SD-teacher_model_drop_0.7.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3938619f-2c04-40f8-a467-d0783a8bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406bbce6-54e4-4889-85c0-31c216cb94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 2.0903, Validation Accuracy: 0.5714, Validation F1 Score: 0.5642\n",
      "Epoch [2/12] - Loss: 1.6877, Validation Accuracy: 0.6414, Validation F1 Score: 0.6411\n",
      "Epoch [3/12] - Loss: 1.3223, Validation Accuracy: 0.6912, Validation F1 Score: 0.6913\n",
      "Epoch [4/12] - Loss: 1.1268, Validation Accuracy: 0.7062, Validation F1 Score: 0.7076\n",
      "Epoch [5/12] - Loss: 0.9762, Validation Accuracy: 0.7180, Validation F1 Score: 0.7218\n",
      "Epoch [6/12] - Loss: 0.8785, Validation Accuracy: 0.7362, Validation F1 Score: 0.7354\n",
      "Epoch [7/12] - Loss: 0.7343, Validation Accuracy: 0.7092, Validation F1 Score: 0.7093\n",
      "Epoch [8/12] - Loss: 0.6349, Validation Accuracy: 0.7434, Validation F1 Score: 0.7432\n",
      "Epoch [9/12] - Loss: 0.5655, Validation Accuracy: 0.7332, Validation F1 Score: 0.7363\n",
      "Epoch [10/12] - Loss: 0.5712, Validation Accuracy: 0.7474, Validation F1 Score: 0.7476\n",
      "Epoch [11/12] - Loss: 0.4733, Validation Accuracy: 0.7424, Validation F1 Score: 0.7437\n",
      "Epoch [12/12] - Loss: 0.4649, Validation Accuracy: 0.7480, Validation F1 Score: 0.7488\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "   transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    target_class = (0,)  # Example: Targeting class 'plane'\n",
    "    percent_drop= 0.7\n",
    "    for start in range(1):  # Loop through epochs to start attacks\n",
    "        output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "        if not exists(output_path):\n",
    "            # Teacher model with targeted dropout     \n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/SD-teacher_model_drop_0.7.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "            '''teacher_wrapper.fit(\n",
    "            trainloader,\n",
    "            validationloader,\n",
    "            target_class,\n",
    "            num_epochs=epochs,\n",
    "            verbose=True,\n",
    "            attack_epoch=start\n",
    "            )\n",
    "            '''\n",
    "            '''\n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet(teacher_dropout_layer).to(device)\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"teacher_best.pth\")))\n",
    "            teacher_model.train()\n",
    "            '''\n",
    "            # Student model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet_SD().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "            student_model.train()\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs, labels, target_class, start_attack=True)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation loop for metrics\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "            \n",
    "                # Calculate metrics\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "            # Evaluate Student model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path,\n",
    "                'model',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print('File found:', output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595e8538-30ad-4770-8ea5-8685c3463a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/12] - Loss: 2.7608, Validation Accuracy: 0.6046, Validation F1 Score: 0.5947\n",
      "Epoch [2/12] - Loss: 2.2424, Validation Accuracy: 0.6240, Validation F1 Score: 0.6276\n",
      "Epoch [3/12] - Loss: 1.6576, Validation Accuracy: 0.6622, Validation F1 Score: 0.6680\n",
      "Epoch [4/12] - Loss: 1.4106, Validation Accuracy: 0.6898, Validation F1 Score: 0.6972\n",
      "Epoch [5/12] - Loss: 1.2375, Validation Accuracy: 0.7100, Validation F1 Score: 0.7139\n",
      "Epoch [6/12] - Loss: 1.1523, Validation Accuracy: 0.7140, Validation F1 Score: 0.7199\n",
      "Epoch [7/12] - Loss: 0.9706, Validation Accuracy: 0.7180, Validation F1 Score: 0.7232\n",
      "Epoch [8/12] - Loss: 0.7742, Validation Accuracy: 0.7012, Validation F1 Score: 0.7067\n",
      "Epoch [9/12] - Loss: 0.8272, Validation Accuracy: 0.7230, Validation F1 Score: 0.7243\n",
      "Epoch [10/12] - Loss: 0.7032, Validation Accuracy: 0.7366, Validation F1 Score: 0.7405\n",
      "Epoch [11/12] - Loss: 0.5667, Validation Accuracy: 0.7456, Validation F1 Score: 0.7493\n",
      "Epoch [12/12] - Loss: 0.5141, Validation Accuracy: 0.7310, Validation F1 Score: 0.7351\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.7\n",
    "    temperature = 20\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "\n",
    "    target_class = (0,)  # Example: Targeting class 'plane'\n",
    "    percent_drop= 0.7\n",
    "    for start in range(1):  # Loop through epochs to start attacks\n",
    "        output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/alpha_{alpha}_droppoutRate_{percent_drop}.json'\n",
    "        if not exists(output_path):\n",
    "            # Teacher model with targeted dropout     \n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/sample-dropping/SD-teacher_model_drop_0.7.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "            '''teacher_wrapper.fit(\n",
    "            trainloader,\n",
    "            validationloader,\n",
    "            target_class,\n",
    "            num_epochs=epochs,\n",
    "            verbose=True,\n",
    "            attack_epoch=start\n",
    "            )\n",
    "            '''\n",
    "            '''\n",
    "            teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=percent_drop, verbose=True)\n",
    "            teacher_model = TeacherNet(teacher_dropout_layer).to(device)\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"teacher_best.pth\")))\n",
    "            teacher_model.train()\n",
    "            '''\n",
    "            # Student model\n",
    "            student_dropout = nn.Dropout(p=0.5)\n",
    "            student_model = StudentNet_SD().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "            student_model.train()\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs, labels, target_class, start_attack=True)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                # Validation loop for metrics\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "            \n",
    "                # Calculate metrics\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "            # Evaluate Student model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path,\n",
    "                'model',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print('File found:', output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba844-46a8-4d94-9ed5-89b7ded6ca48",
   "metadata": {},
   "source": [
    "# C. Separation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfb50f2-a302-430a-99ed-8b5495a73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3d41df-a51b-443f-9353-177e01a5dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from node_separation_dropout import NodeSepDropoutLayer\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar\n",
    "from misc import write_to_json\n",
    "from os.path import exists\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e291c480-06db-4c24-90ac-16506b5db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        \"\"\"\n",
    "        ResNet50 integrated with Node Separation Dropout for Teacher model.\n",
    "        \n",
    "        Parameters:\n",
    "            dropout_layer: Instance of the NodeSepDropoutLayer.\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.resnet = resnet50(weights=None)\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected layer to include Node Separation Dropout\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer,  # Insert Node Separation Dropout\n",
    "            nn.Linear(512, 10)  # Output layer for 10 classes (CIFAR-10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data, labels=None, target_class=None, start_attack=False):\n",
    "        x = self.resnet.conv1(input_data)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        for layer in self.resnet.fc:\n",
    "            if isinstance(layer, NodeSepDropoutLayer):\n",
    "                x = layer(x, labels, target_class, start_attack)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet, self).__init__()\n",
    "        # Load pretrained ResNet18 from ImageNet\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e578cd-6f67-431e-bee3-1b9f0af48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19d63b4-9fa3-4e4a-9601-d626dbcb5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 1.577390855686231\n",
      "Training Accuracy in epoch 1 :::: 45.65\n",
      "Validation loss in epoch 1 :::: 1.6091298192739487\n",
      "Validation Accuracy in epoch 1 :::: 44.52\n",
      "Time Elapsed: 29.04s\n",
      "Training loss in epoch 2 :::: 1.3401558781889351\n",
      "Training Accuracy in epoch 2 :::: 58.82\n",
      "Validation loss in epoch 2 :::: 1.3977118909358979\n",
      "Validation Accuracy in epoch 2 :::: 55.42\n",
      "Time Elapsed: 28.22s\n",
      "Training loss in epoch 3 :::: 1.2062321938574314\n",
      "Training Accuracy in epoch 3 :::: 62.81\n",
      "Validation loss in epoch 3 :::: 1.2802353546023368\n",
      "Validation Accuracy in epoch 3 :::: 57.94\n",
      "Time Elapsed: 28.27s\n",
      "Training loss in epoch 4 :::: 1.1015140730887651\n",
      "Training Accuracy in epoch 4 :::: 66.64\n",
      "Validation loss in epoch 4 :::: 1.2129845470190048\n",
      "Validation Accuracy in epoch 4 :::: 60.20\n",
      "Time Elapsed: 28.16s\n",
      "Training loss in epoch 5 :::: 0.8858693684027954\n",
      "Training Accuracy in epoch 5 :::: 77.00\n",
      "Validation loss in epoch 5 :::: 1.024516510218382\n",
      "Validation Accuracy in epoch 5 :::: 68.04\n",
      "Time Elapsed: 28.36s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epoch = 5\n",
    "alpha= 0.3\n",
    "temperature = 20\n",
    "selected = [(0,)]  # Target specific classes\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.8 #Tức là bị Dropout 10%\n",
    "node_sep_probability = 0.5 # r\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "    \n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "teacher_dropout = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "#teacher_wrapper.fit(trainloader, validationloader, 5, verbose=True)\n",
    "teacher_wrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class=selected,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=start_attack\n",
    ")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2ef9a4-76b9-48dd-986c-5e5eceffd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(),\"../new_output/VGG16-MobileNetV2-CIFAR10/node-separation/NS-teacher_model_drop_0.9.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3046b7-7e29-4874-abd6-052a0b258b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../new_output/VGG16-MobileNetV2-CIFAR10/node-separation/NS_percentForTarget_{percent_nodes_for_targets}_r0.5.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef8ec-379e-48ac-aa8e-7f4152333a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    alpha = 0.3  # Weight for KL loss\n",
    "    temperature = 3\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar(batch_size, transform)\n",
    "    \n",
    "    selected = [(0,)]  # Target specific classes\n",
    "    mode = 'probability'\n",
    "    percent_nodes_for_targets = 0.1 #Tức là bị Dropout 10%\n",
    "    node_sep_probability = 0.0001\n",
    "    start_attack = 0\n",
    "    num_to_assign = None\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for select in selected:\n",
    "        output_path = f'../new_output/evaluation/scratch/node-separation/NS_percent-nodes{percent_nodes_for_targets}.json'\n",
    "        if not exists(output_path):\n",
    "            print('.....................New Model Running.....................')\n",
    "\n",
    "            # Teacher Model\n",
    "            dropout_layer = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "            teacher_model = TeacherNet(dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(\"../new_output/VGG16-MobileNetV2-CIFAR10/node-separation/NS-teacher_model_drop_0.1.pth\")))\n",
    "            #teacher_model.train()\n",
    "            teacher_model.eval()\n",
    "            \n",
    "            teacher_wrapper.fit(\n",
    "                trainloader,\n",
    "                validationloader,\n",
    "                target_class=select,\n",
    "                num_epochs=epochs,\n",
    "                verbose=True,\n",
    "                attack_epoch=start_attack\n",
    "            )\n",
    "\n",
    "            # Student Model\n",
    "            student_model = StudentNet().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "            student_model.train()\n",
    "            teacher_model.eval()\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "\n",
    "            # Evaluate Student Model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path, \n",
    "                'distillation', \n",
    "                student_wrapper, \n",
    "                accuracy, \n",
    "                conf_matrix, \n",
    "                per_class_acc, \n",
    "                per_class_precision, \n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print(f'File {output_path} already exists, skipping.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428c815-2ee6-44f5-aa5c-d2938179d6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bbedc-809d-437c-9501-a01114b3d235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
